var documenterSearchIndex = {"docs":
[{"location":"references/#References","page":"References","title":"References","text":"O. Guba, M. Taylor and A. St-Cyr. Optimization-based limiters for the spectral element method. Journal of computational physics 267, 176–195 (2014).\n\n\n\nI. Higueras and T. Roldán. New third order low-storage SSP explicit Runge-Kutta methods, arXiv preprint arXiv:1809.04807 (2018).\n\n\n\nM. Schlegel, O. Knoth, M. Arnold and R. Wolke. Implementation of multirate time integration methods for air pollution modelling. Geoscientific Model Development 5, 1395–1405 (2012).\n\n\n\nJ. Wensch, O. Knoth and A. Galant. Multirate infinitesimal step methods for atmospheric flow simulation. BIT Numerical Mathematics 49, 449–473 (2009).\n\n\n\nO. Knoth and J. Wensch. Generalized split-explicit Runge–Kutta methods for the compressible Euler equations. Monthly Weather Review 142, 2067–2081 (2014).\n\n\n\nL. J. Wicker and W. C. Skamarock. A time-splitting scheme for the elastic equations incorporating second-order Runge–Kutta time differencing. Monthly Weather Review 126, 1992–1999 (1998).\n\n\n\nL. J. Wicker and W. C. Skamarock. Time-splitting methods for elastic models using forward time schemes. Monthly Weather Review 130, 2088–2097 (2002).\n\n\n\nU. M. Ascher, S. J. Ruuth and R. J. Spiteri. Implicit-explicit Runge-Kutta methods for time-dependent partial differential equations. Applied Numerical Mathematics 25, 151–167 (1997).\n\n\n\nA. J. Steyer, C. J. Vogl, M. Taylor and O. Guba. Efficient IMEX Runge-Kutta methods for nonhydrostatic dynamics, arXiv (2019).\n\n\n\nL. Pareschi and G. Russo. Implicit–explicit Runge–Kutta schemes and applications to hyperbolic systems with relaxation. Journal of Scientific Computing 25, 129–155 (2005).\n\n\n\nD. J. Gardner, J. E. Guerra, F. P. Hamon, D. R. Reynolds, P. A. Ullrich and Woodward. Implicit–explicit (IMEX) Runge–Kutta methods for non-hydrostatic atmospheric models. Geoscientific Model Development 11, 1497–1515 (2018).\n\n\n\nS. Conde, S. Gottlieb, Z. J. Grant and J. N. Shadid. Implicit and Implicit–Explicit Strong Stability Preserving Runge–Kutta Methods with High Linear Order. Journal of Scientific Computing 73, 667–690 (2017).\n\n\n\nC. J. Vogl, A. Steyer, D. R. Reynolds, P. A. Ullrich and C. S. Woodward. Evaluation of implicit-explicit additive runge-kutta integrators for the HOMME-NH dynamical core. Journal of Advances in Modeling Earth Systems 11, 4228–4244 (2019).\n\n\n\nO. Guba, M. A. Taylor, A. M. Bradley, P. A. Bosler and A. Steyer. A framework to evaluate IMEX schemes for atmospheric models. Geoscientific Model Development 13, 6467–6480 (2020).\n\n\n\nF. X. Giraldo, J. F. Kelly and E. M. Constantinescu. Implicit-explicit formulations of a three-dimensional          nonhydrostatic unified model of the atmosphere (NUMA). SIAM Journal on Scientific Computing 35, B1162–B1194 (2013).\n\n\n\nC. A. Kennedy and M. H. Carpenter. Higher-order additive Runge–Kutta schemes for ordinary          differential equations. Applied Numerical Mathematics 136, 183–205 (2019).\n\n\n\nC.-W. Shu and S. Osher. Efficient implementation of essentially non-oscillatory shock-capturing schemes. Journal of computational physics 77, 439–471 (1988).\n\n\n\nK. Heun. Neue Methoden zur approximativen Integration der    Differentialgleichungen einer unabhängigen Veränderlichen. Z. Math. Phys 45, 23–38 (1900).\n\n\n\nE. Süli and D. Mayers. An Introduction to Numerical Analysis (Cambridge University Press, 2003); p. 352.\n\n\n\nM. H. Carpenter and C. A. Kennedy. Fourth-order 2N-storage Runge–Kutta schemes. Technical Report NASA TM-109112 (National Aeronautics and Space Administration, Langley Research Center, Hampton, VA, 1994).\n\n\n\nJ. Niegemann, R. Diehl and K. Busch. Efficient low-storage Runge–Kutta schemes with optimized stability regions. Journal of Computational Physics 231, 364–372 (2012).\n\n\n\n","category":"section"},{"location":"api/callbacks/#Callbacks","page":"Callbacks","title":"Callbacks","text":"","category":"section"},{"location":"api/callbacks/#Interfaces","page":"Callbacks","title":"Interfaces","text":"","category":"section"},{"location":"api/callbacks/#Callbacks-2","page":"Callbacks","title":"Callbacks","text":"","category":"section"},{"location":"api/callbacks/#ClimaTimeSteppers.Callbacks","page":"Callbacks","title":"ClimaTimeSteppers.Callbacks","text":"ClimaTimeSteppers.Callbacks\n\nA suite of callback functions to be used with the ClimaTimeSteppers.jl ODE solvers.\n\n\n\n\n\n","category":"module"},{"location":"api/callbacks/#ClimaTimeSteppers.Callbacks.initialize!","page":"Callbacks","title":"ClimaTimeSteppers.Callbacks.initialize!","text":"ClimaTimeSteppers.Callbacks.initialize!(f!::F, integrator)\n\nInitialize a callback event for callbacks of type F. By default this does nothing, but can be extended for new callback events.\n\n\n\n\n\n","category":"function"},{"location":"api/callbacks/#ClimaTimeSteppers.Callbacks.finalize!","page":"Callbacks","title":"ClimaTimeSteppers.Callbacks.finalize!","text":"ClimaTimeSteppers.Callbacks.finalize!(f!::F, integrator)\n\nFinalize a callback event for callbacks of type F. By default this does nothing, but can be extended for new callback events.\n\n\n\n\n\n","category":"function"},{"location":"api/callbacks/#ClimaTimeSteppers.Callbacks.EveryXWallTimeSeconds","page":"Callbacks","title":"ClimaTimeSteppers.Callbacks.EveryXWallTimeSeconds","text":"EveryXWallTimeSeconds(\n    f!,\n    Δwt,\n    comm_ctx::ClimaComms.AbstractCommsContext;\n    atinit=false\n)\n\nTrigger f!(integrator) every Δwt wallclock seconds.\n\nAn ClimaComms context must be provided to synchronize timing across all ranks.\n\nCallbacks.initialize! and Callbacks.finalize! can be defined for f!.\n\nIf atinit=true, then f!(integrator) will additionally be triggered at initialization, otherwise the first trigger will be after Δwt seconds.\n\n\n\n\n\n","category":"function"},{"location":"api/callbacks/#ClimaTimeSteppers.Callbacks.EveryXSimulationTime","page":"Callbacks","title":"ClimaTimeSteppers.Callbacks.EveryXSimulationTime","text":"EveryXSimulationTime(f!, Δt; atinit=false)\n\nTrigger f!(integrator) every Δt simulation time.\n\nCallbacks.initialize! and Callbacks.finalize! can be defined for f!.\n\nIf atinit=true, then f! will additionally be triggered at initialization. Otherwise the first trigger will be after Δt simulation time.\n\n\n\n\n\n","category":"function"},{"location":"api/callbacks/#ClimaTimeSteppers.Callbacks.EveryXSimulationSteps","page":"Callbacks","title":"ClimaTimeSteppers.Callbacks.EveryXSimulationSteps","text":"EveryXSimulationSteps(f!, Δsteps; atinit=false)\n\nTrigger f!(integrator) every Δsteps simulation steps.\n\nCallbacks.initialize! and Callbacks.finalize! can be defined for f!.\n\nIf atinit==true, then f! will additionally be triggered at initialization. Otherwise the first trigger will be after Δsteps.\n\n\n\n\n\n","category":"function"},{"location":"algorithm_formulations/ode_solvers/#ODE-Solvers","page":"ODE Solvers","title":"ODE Solvers","text":"","category":"section"},{"location":"algorithm_formulations/ode_solvers/#Standard-IMEX-ARK","page":"ODE Solvers","title":"Standard IMEX ARK","text":"An ordinary differential equation (ODE) is an equation of the form\n\nfracddtu(t) = T(u(t) t)\n\nwhere u(t) is called the state at time t, and T(u(t) t) is called the tendency of the state at time t.\n\nThe simplest method for numerically solving this equation with a finite timestep Delta t is the forward Euler method, in which the equation is approximated as\n\nfracu(t + Delta t) - u(t)Delta t approx T(u(t) t)\n\nGiven the value of u_0 = u(t_0) at some time t_0, the approximation implies that u(t_0 + Delta t) approx hatu, where\n\nhatu = u_0 + Delta t T(u_0 t_0)\n\nAn alternative approximation is given by the backward Euler method:\n\nfracu(t + Delta t) - u(t)Delta t approx T(u(t + Delta t) t + Delta t)\n\nWith this approximation, u(t_0 + Delta t) approx hatu, where hatu is now the solution to the equation\n\nu_0 + Delta t T(hatu t_0 + Delta t) - hatu = 0\n\nUnlike the forward Euler method, in which hatu is directly computed based on the known state u_0, the backward Euler method involves solving a root equation in order to obtain the value of hatu. So, the forward Euler method is called an explicit method, whereas the backward Euler method is called an implicit method.\n\nIn general, T can be a complicated nonlinear function of u(t) and t, and it is usually not possible to solve the backward Euler method's implicit equation for hatu analytically. Instead, it is often necessary to use an iterative root-finding algorithm like Newton's method to solve for hatu. Although this is more computationally expensive than using the forward Euler method to directly obtain hatu from u_0, it is often necessary to deal with the problem of stiffness.\n\nRoughly speaking, a tendency T is stiff when the forward Euler method requires a relatively small timestep Delta t to obtain a reasonably accurate solution, where \"relatively small\" means that it is smaller than one would expect based on the rate at which u(t) changes over time. When T is not stiff, a small timestep is only required when u(t) changes quickly with respect to t, and a larger timestep can be used when u(t) changes slowly. The backward Euler method is more stable than the forward Euler method, which means that it is usually able to take larger timesteps, especially when T is stiff.\n\nAs a compromise between the simplicity of the forward Euler method and the stability of the backward Euler method, it is common to use the implicit-explicit (IMEX) Euler method. This involves splitting T into an explicit tendency T_textexp and an implicit tendency T_textimp, so that T(u(t) t) = T_textexp(u(t) t) + T_textimp(u(t) t), and making the approximation\n\nfracu(t + Delta t) - u(t)Delta t approx T_textexp(u(t) t) + T_textimp(u(t + Delta t) t + Delta t)\n\nWith this approximation, the implicit equation for hatu becomes\n\nu_0 + Delta t T_textexp(u_0 t_0) + Delta t T_textimp(hatu t_0 + Delta t) - hatu = 0\n\nNote that T_textexp is evaluated explicitly at the known state u_0, while T_textimp is evaluated implicitly at the unknown state hatu.\n\nBoth the forward and backward Euler methods (and, by extension, the IMEX Euler method) are first-order methods, which means that the errors of their approximations are proportional to Delta t when Delta t is sufficiently close to 0.[1] In order to achieve a reasonable accuracy with fewer timesteps, it is common to use higher-order methods, where a method of order p will have an error that is proportional to (Delta t)^p for small values of Delta t. The simplest higher-order generalization of the forward and backward Euler methods is a Runge-Kutta method, in which there are s stages U_1 U_2 ldots U_s that satisfy\n\n[1]: \nMore precisely, the local truncation error of the forward and backward Euler methods after a single timestep is Oleft((Delta t)^2right), which means that u(t_0 + Delta t) - hatu  C (Delta t)^2 for all Delta t  D, where C and D are some constants. On the other hand, the global truncation error after taking enough timesteps to go from t_0 to some t_1  t_0 is O(Delta t). This is because there are (t_1 - t_0)  Delta t timesteps between t_0 and t_1, and, if each timestep has a local truncation error of Oleft((Delta t)^2right), then the error after Oleft((Delta t)^-1right) timesteps must be O(Delta t). In general, for a Runge-Kutta method (or ARK method) of order p, the local truncation error is Oleft((Delta t)^p + 1right), and the global truncation error is Oleft((Delta t)^pvphantom1right).\n\nU_i = u_0 + Delta t sum_j = 1^s a_ij T(U_j t_0 + Delta t c_j)\n\nand u(t_0 + Delta t) is approximated as\n\nhatu = u_0 + Delta t sum_i = 1^s b_i T(U_i t_0 + Delta t c_i)\n\nThe coefficients a_ij, b_i, and c_i of a Runge-Kutta method can be summarized in a Butcher tableau:\n\nbeginarraycc c c c c c_1  a_11  a_12  cdots  a_1s - 1  a_1s  c_2  a_21  a_22  cdots  a_2s - 1  a_2s  c_3  a_31  a_32  cdots  a_3s - 1  a_3s  vdots  vdots  vdots  ddots  vdots  vdots  c_s  a_s1  a_s2  cdots  a_ss - 1  a_ss  hline  b_1  b_2  cdots  b_s - 1  b_s endarray\n\nSince solving a system of s coupled equations for the stages U_i is usually impractical, many of the a_ij coefficients are set to 0 in commonly used Runge-Kutta methods. When a_ij = 0 for all j geq i, the equation for U_i simplifies to the explicit formula\n\nU_i = u_0 + Delta t sum_j = 1^i - 1 a_ij T(U_j t_0 + Delta t c_j)\n\nThis is called an explicit Runge-Kutta (ERK) method. When a_ij = 0 for all j  i, the implicit equation for U_i becomes uncoupled from the equations for the other stages, and it can be rewritten as\n\nu_0 + Delta t sum_j = 1^i - 1 a_ij T(U_j t_0 + Delta t c_j) + Delta t a_ii T(U_i t_0 + Delta t c_i) - U_i = 0\n\nSince the only unknown tendency in this equation comes from the diagonal coefficient a_ii, this is called a diagonally implicit Runge-Kutta (DIRK) method. There are many different categories of DIRK methods, such as explicit first stage DIRK (EDIRK), where a_11 = 0, singly DIRK (SDIRK), where a_11 = a_22 = ldots = a_ss = gamma for some constant gamma, and ESDIRK, where a_11 = 0 and a_22 = ldots = a_ss = gamma.\n\nJust as the forward and backward Euler methods can be combined into the IMEX Euler method, two Runge-Kutta methods can be combined into an additive Runge-Kutta (ARK) method. If the first method is explicit and the second is implicit, the result is an IMEX ARK method. We will only be considering IMEX ARK methods where the implicit part is DIRK. If the DIRK method has coefficients a_ij, b_i, and c_i, and the ERK method has coefficients tildea_ij, tildeb_i, and tildec_i, the IMEX ARK method approximates u(t_0 + Delta t) as\n\nhatu = u_0 + Delta t sum_i = 1^s left(tildeb_i T_textexp(U_i t_0 + Delta t tildec_i) + b_i T_textimp(U_i t_0 + Delta t c_i)right)\n\nwhere the implicit equation for U_i is now\n\nu_0 + Delta t sum_j = 1^i - 1 left(tildea_ij T_textexp(U_j t_0 + Delta t tildec_j) + a_ij T_textimp(U_j t_0 + Delta t c_j)right) + Delta t a_ii T_textimp(U_i t_0 + Delta t c_i) - U_i = 0","category":"section"},{"location":"algorithm_formulations/ode_solvers/#Adding-DSS","page":"ODE Solvers","title":"Adding DSS","text":"It is often necessary to filter the state so that it satisfies some particular constraint before it is used to evaluate a tendency. In our case, the state is a collection of values defined across a spatially discretized domain. When we use a continuous Galerkin (CG) spectral element discretization, we must ensure that the state is continuous across element boundaries before we use it to compute any tendency. We can turn any state that is discontinuous across element boundaries into a continuous one by applying a direct stiffness summation (DSS) to it. Applying DSS to hatu in the IMEX ARK method is straightforward:\n\nhatu = textrmDSSleft(u_0 + Delta t sum_i = 1^s left(tildeb_i T_textexp(U_i t_0 + Delta t tildec_i) + b_i T_textimp(U_i t_0 + Delta t c_i)right)right)\n\nApplying DSS to each stage U_i is a bit trickier. Ideally, we would use the equation\n\ntextrmDSSleft(beginaligned  u_0 + Delta t sum_j = 1^i - 1 left(tildea_ij T_textexp(U_j t_0 + Delta t tildec_j) + a_ij T_textimp(U_j t_0 + Delta t c_j)right) +   Delta t a_ii T_textimp(U_i t_0 + Delta t c_i) endalignedright) - U_i = 0\n\nsince this would ensure that the implicit tendency T_textimp gets evaluated at a continuous stage U_i. However, this equation is more challenging to solve than the original one, since it involves applying DSS, which is usually a more complicated function than T_textimp, to an unknown quantity. So, we instead use the equation\n\nbeginaligned textrmDSSleft(u_0 + Delta t sum_j = 1^i - 1 left(tildea_ij T_textexp(U_j t_0 + Delta t tildec_j) + a_ij T_textimp(U_j t_0 + Delta t c_j)right)right) +   Delta t a_ii T_textimp(U_i t_0 + Delta t c_i) - U_i = 0 endaligned\n\nThis equation is identical to the previous one only when T_textimp preserves the effects of DSS. That is to say, if evaluating T_textimp at a continuous stage U_i produces a continuous tendency, then it is not necessary to apply DSS after adding this tendency to a continuous quantity. This also assumes that the root-finding algorithm used to compute U_i preserves the effects of DSS, which will usually be the case as long as T_textimp does so. In general, one could replace DSS with a filter that enforces some other constraint, as long as that constraint is preserved by T_textimp. The constraint must also be preserved by addition and by multiplication with a constant, which are the only other operations used to compute U_i after applying the filter.\n\nNote that this method of enforcing a constraint is not mathematically rigorous, as it does not necessarily maintain the convergence properties of the IMEX ARK method. This is because DSS effectively acts like a tendency on each stage U_i, but, unlike the actual tendencies T_textexp and T_textimp, the effects of DSS on the previous stages U_1 U_2 ldots U_i - 1 are not accounted for when computing U_i. The proper way to enforce a constraint would be to extend the ODE to a differential-algebraic equation (DAE) by adding an algebraic equation F(u(t) t) = 0 that can only be satisfied when u(t) obeys the constraint, and then solving the DAE using an appropriate numerical method. However, this route would be significantly more computationally expensive than our method. Moreover, we have observed that the effects of DSS are sufficiently small to not noticeably disrupt the convergence of IMEX ARK methods in our test cases, though this will not necessarily be the case if DSS is replaced with another filter.","category":"section"},{"location":"algorithm_formulations/ode_solvers/#Adding-a-Limiter","page":"ODE Solvers","title":"Adding a Limiter","text":"In addition to filtering the state, it is often necessary to filter part of the tendency, but in a way that depends on the state to which the tendency is being added. In our case, because we use a spectral element discretization, part of the explicit tendency can add spurious oscillations to each stage. We can limit these oscillations by using a monotonicity-preserving limiter (see [1]), which is a function textrmlim_u(t) that, when used with an appropriate tendency T_textlim(u(t) t) and a sufficiently small constant C, satisfies the inequalities\n\nbeginaligned textrmminbiggl(textrmlim_u(t)bigl(u(t) + C T_textlim(u(t) t)bigr)biggr) geq textrmminbigl(u(t)bigr) text and  textrmmaxbiggl(textrmlim_u(t)bigl(u(t) + C T_textlim(u(t) t)bigr)biggr) leq textrmmaxbigl(u(t)bigr) endaligned\n\nIn other words, applying the limiter to a state incremented by the limited tendency, u(t) + C T_textlim(u(t) t), ensures that the extrema of the incremented state do not exceed the extrema of the unincremented state, u(t). Note that the process of incrementing a state in this way is used by the forward Euler method with Delta t = C and T = T_textlim, which is why it is called an Euler step. Since spurious oscillations usually cause the extrema of the state to grow, this is an effective mechanism for eliminating such oscillations. Note that the limiter can only preserve monotonicity by comparing the incremented state to the unincremented state, which means that the effects of the limiter are a function of the unincremented state (hence the subscript in textrmlim_u(t)).\n\nUnfortunately, there is no mathematically correct way to incorporate the use of a limiter into a general IMEX ARK method. The most straightforward approach is to split T_textexp into two tendencies T_textexp and T_textlim, to modify the equation for hatu to\n\nbeginaligned hatu =  textrmlim_u_0left(u_0 + Delta t sum_i = 1^s tildeb_i T_textlim(U_i t_0 + Delta t tildec_i)right) +   Delta t sum_i = 1^s left(tildeb_i T_textexp(U_i t_0 + Delta t tildec_i) + b_i T_textimp(U_i t_0 + Delta t c_i)right) endaligned\n\nand to modify the equation for U_i to\n\nbeginaligned textrmlim_u_0left(u_0 + Delta t sum_j = 1^i - 1 tildea_ij T_textlim(U_j t_0 + Delta t tildec_j)right) +   Delta t sum_j = 1^i - 1 left(tildea_ij T_textexp(U_j t_0 + Delta t tildec_j) + a_ij T_textimp(U_j t_0 + Delta t c_j)right) +   Delta t a_ii T_textimp(U_i t_0 + Delta t c_i) - U_i = 0 endaligned\n\nNot only does this approach not maintain the convergence properties of the IMEX ARK method (for the same reason as DSS above),[2] but it also does not even use the limiter in a way that allows it to preserve monotonicity. That is, the argument of textrmlim_u_0 does not have the form needed to satisfy the min and max constraints given above, since it involves evaluating the limited tendency at states that are not the unincremented state. As luck would have it, we have observed that the limiter, even when used in such an incorrect manner, is still able to substantially reduce spurious oscillations in our test cases, though it is not able to perform as well as it would if it were used correctly.\n\n[2]: \nBy Godunov's theorem, no monotonicity-preserving linear numerical method can have an order greater than 1. Since textrmlim_u_0 will usually be a nonlinear function, this is not a linear numerical method. However, it is a rough approximation of the unmodified ARK method, so it is likely that Godunov's theorem will still apply; i.e., we do not expect to observe an order greater than 1 when using a limiter.\n\nIn order to use the limiter \"more correctly\", we constrain the ERK Butcher tableau coefficients to have the following form:\n\nbeginarraycc c c c c tildec_1  0  0  cdots  0  0  tildec_2  beta_1  0  cdots  0  0  tildec_3  beta_1 beta_2  beta_2  cdots  0  0  vdots  vdots  vdots  ddots  vdots  vdots  tildec_s  beta_1 beta_2 ldots beta_s - 1  beta_2 ldots beta_s - 1  cdots  beta_s - 1  0  hline  beta_1 beta_2 ldots beta_s - 1 beta_s  beta_2 ldots beta_s - 1 beta_s  cdots  beta_s - 1 beta_s  beta_s endarray\n\nIf all of the coefficients beta_1 beta_2 ldots beta_s are nonnegative, and if the resulting ERK method converges, it is called a strong stability preserving Runge-Kutta (SSPRK) method.[3] Moreover, if the ERK method is SSPRK, then the overall IMEX ARK method is called an IMEX SSPRK method.\n\n[3]: \nThis is really a low-storage SSPRK method that only requires two registers for storing states, using one of the registers to store u_0; this is an example of a 2N^* method (see [2]). A general SSPRK method has just as many independent coefficients as a general ERK method, though its coefficients are used somewhat differently, in a way that makes them more amenable to limiters. We restrict ourselves to s independent coefficients beta_i merely for the sake of simplicity. In the future, we might want to generalize to arbitrary SSPRK methods.\n\nNow, in order to simplify our notation, we will define s + 1 values tildeU_1 tildeU_2 ldots tildeU_s + 1, where\n\ntildeU_i = begincases displaystyle u_0 + Delta t sum_j = 1^i - 1 tildea_ij T_textexp(U_j t_0 + Delta t tildec_j)  i  s + 1  displaystyle u_0 + Delta t sum_i = 1^s tildeb_i T_textexp(U_i t_0 + Delta t tildec_i)  i = s + 1 endcases\n\nThis allows us to rewrite the IMEX ARK equation for hatu as\n\nhatu = tildeU_s + 1 + Delta t sum_i = 1^s b_i T_textimp(U_i t_0 + Delta t c_i)\n\nand to rewrite the equation for U_i as\n\ntildeU_i + Delta t sum_j = 1^i - 1 a_ij T_textimp(U_j t_0 + Delta t c_j) + Delta t a_ii T_textimp(U_i t_0 + Delta t c_i) - U_i = 0\n\nIf we constrain the IMEX ARK method to an IMEX SSPRK method, we can express tildeb_i as\n\ntildeb_i = begincases beta_s tildea_si  i  s  beta_s  i = s endcases\n\nwhich means that\n\nbeginaligned tildeU_s + 1 =  u_0 + Delta t sum_i = 1^s - 1 tildeb_i T_textexp(U_i t_0 + Delta t tildec_i) + Delta t tildeb_s T_textexp(U_s t_0 + Delta t tildec_s) =   u_0 + Delta t beta_s sum_i = 1^s - 1 tildea_si T_textexp(U_i t_0 + Delta t tildec_i) + Delta t beta_s T_textexp(U_s t_0 + Delta t tildec_s) =   (1 - beta_s) u_0 + beta_s left(tildeU_s + Delta t T_textexp(U_s t_0 + Delta t tildec_s)right) endaligned\n\nIn addition, for all i  1,\n\ntildea_ij = begincases beta_i - 1 tildea_i - 1j  j  i - 1  beta_i - 1  j = i - 1 endcases\n\nwhich means that\n\nbeginaligned tildeU_i =  u_0 + Delta t sum_j = 1^i - 2 tildea_ij T_textexp(U_j t_0 + Delta t tildec_j) + Delta t tildea_ii - 1 T_textexp(U_i - 1 t_0 + Delta t tildec_i - 1) =   u_0 + Delta t beta_i - 1 sum_j = 1^i - 2 tildea_i - 1j T_textexp(U_j t_0 + Delta t tildec_j) + Delta t beta_i - 1 T_textexp(U_i - 1 t_0 + Delta t tildec_i - 1) =   (1 - beta_i - 1) u_0 + beta_i - 1 left(tildeU_i - 1 + Delta t T_textexp(U_i - 1 t_0 + Delta t tildec_i - 1)right) endaligned\n\nSince tildeU_1 = u_0, constraining the IMEX ARK method to an IMEX SSPRK method allows us to express tildeU_i as\n\ntildeU_i = begincases u_0  i = 1  (1 - beta_i - 1) u_0 + beta_i - 1 left(tildeU_i - 1 + Delta t T_textexp(U_i - 1 t_0 + Delta t tildec_i - 1)right)  i  1 endcases\n\nTo incorporate the use of a limiter into the IMEX SSPRK method, we split T_textexp into T_textexp and T_textlim, and we modify the equation for tildeU_i to\n\ntildeU_i = begincases u_0  i = 1  beginaligned  (1 - beta_i - 1) u_0 +   quadbeta_i - 1 left(textrmlim_tildeU_i - 1left(tildeU_i - 1 + Delta t T_textlim(U_i - 1 t_0 + Delta t tildec_i - 1)right) + Delta t T_textexp(U_i - 1 t_0 + Delta t tildec_i - 1)right) endaligned  i  1 endcases\n\nIn this equation, the limiter is being applied to a limited tendency evaluated at U_i - 1, but with tildeU_i - 1 as the unincremented state. If there is no implicit tendency, so that T_textimp is always 0, then U_i - 1 = tildeU_i - 1, and the limiter is able to properly preserve monotonicity. On the other hand, if there is an implicit tendency, then the limiter will not necessarily preserve monotonicity. That is, the limiter is guaranteed to function properly when the limited tendency is used in a sequence of Euler steps.","category":"section"},{"location":"algorithm_formulations/ode_solvers/#Summary","page":"ODE Solvers","title":"Summary","text":"We will now summarize our IMEX methods when using both DSS and a limiter.","category":"section"},{"location":"algorithm_formulations/ode_solvers/#IMEX-ARK","page":"ODE Solvers","title":"IMEX ARK","text":"Our general IMEX ARK method is defined by two Butcher tableaus:\n\nbeginarraycc c c c c tildec_1  0  0  cdots  0  0  tildec_2  tildea_21  0  cdots  0  0  tildec_3  tildea_31  tildea_32  cdots  0  0  vdots  vdots  vdots  ddots  vdots  vdots  tildec_s  tildea_s1  tildea_s2  cdots  tildea_ss - 1  0  hline  tildeb_1  tildeb_2  cdots  tildeb_s - 1  tildeb_s endarray text and  beginarraycc c c c c c_1  a_11  0  cdots  0  0  c_2  a_21  a_22  cdots  0  0  c_3  a_31  a_32  cdots  0  0  vdots  vdots  vdots  ddots  vdots  vdots  c_s  a_s1  a_s2  cdots  a_ss - 1  a_ss  hline  b_1  b_2  cdots  b_s - 1  b_s endarray\n\nGiven u_0 = u(t_0), it approximates the value of u(t_0 + Delta t) as\n\nhatu = textrmDSSleft(beginaligned  textrmlim_u_0left(u_0 + Delta t sum_i = 1^s tildeb_i T_textlim(U_i t_0 + Delta t tildec_i)right) +   Delta t sum_i = 1^s left(tildeb_i T_textexp(U_i t_0 + Delta t tildec_i) + b_i T_textimp(U_i t_0 + Delta t c_i)right) endalignedright)\n\nwhere U_i is the solution to the equation\n\ntextrmDSSleft(beginaligned  textrmlim_u_0left(u_0 + Delta t sum_j = 1^i - 1 tildea_ij T_textlim(U_j t_0 + Delta t tildec_j)right) +   Delta t sum_j = 1^i - 1 left(tildea_ij T_textexp(U_j t_0 + Delta t tildec_j) + a_ij T_textimp(U_j t_0 + Delta t c_j)right) endalignedright) + Delta t a_ii T_textimp(U_i t_0 + Delta t c_i) - U_i = 0","category":"section"},{"location":"algorithm_formulations/ode_solvers/#IMEX-SSPRK","page":"ODE Solvers","title":"IMEX SSPRK","text":"Our IMEX SSPRK method is defined by two Butcher tableaus:\n\nbeginarraycc c c c c tildec_1  0  0  cdots  0  0  tildec_2  beta_1  0  cdots  0  0  tildec_3  beta_1 beta_2  beta_2  cdots  0  0  vdots  vdots  vdots  ddots  vdots  vdots  tildec_s  beta_1 beta_2 ldots beta_s - 1  beta_2 ldots beta_s - 1  cdots  beta_s - 1  0  hline  beta_1 beta_2 ldots beta_s - 1 beta_s  beta_2 ldots beta_s - 1 beta_s  cdots  beta_s - 1 beta_s  beta_s endarray text and  beginarraycc c c c c c_1  a_11  0  cdots  0  0  c_2  a_21  a_22  cdots  0  0  c_3  a_31  a_32  cdots  0  0  vdots  vdots  vdots  ddots  vdots  vdots  c_s  a_s1  a_s2  cdots  a_ss - 1  a_ss  hline  b_1  b_2  cdots  b_s - 1  b_s endarray\n\nGiven u_0 = u(t_0), it approximates the value of u(t_0 + Delta t) as\n\nhatu = textrmDSSleft(tildeU_s + 1 + Delta t sum_i = 1^s b_i T_textimp(U_i t_0 + Delta t c_i)right)\n\nwhere U_i is the solution to the equation\n\ntextrmDSSleft(tildeU_i + Delta t sum_j = 1^i - 1 a_ij T_textimp(U_j t_0 + Delta t c_j)right) + Delta t a_ii T_textimp(U_i t_0 + Delta t c_i) - U_i = 0\n\nand where\n\ntildeU_i = begincases u_0  i = 1  beginaligned  (1 - beta_i - 1) u_0 +   quadbeta_i - 1 left(textrmlim_tildeU_i - 1left(tildeU_i - 1 + Delta t T_textlim(U_i - 1 t_0 + Delta t tildec_i - 1)right) + Delta t T_textexp(U_i - 1 t_0 + Delta t tildec_i - 1)right) endaligned  i  1 endcases","category":"section"},{"location":"algorithm_formulations/ode_solvers/#Running-Newton's-Method","page":"ODE Solvers","title":"Running Newton's Method","text":"Every implicit equation for U_i has the form f_i(U_i) = 0, where\n\nf_i(x) = R_i + Delta t a_ii T_textimp(x t_0 + Delta t c_i) - x\n\nIn this function, R_i, Delta t a_ii, and t_0 + Delta t c_i are all quantities that do not depend on x. The Jacobian of this function is\n\nW_i(x) = fracddxf_i(x) = Delta t a_ii J_textimp(x t_0 + Delta t c_i) - 1\n\nwhere J_textimp is the Jacobian of the implicit tendency,\n\nJ_textimp(x t) = fracpartialpartial xT_textimp(x t)\n\nThe value of U_i can be computed by running Newton's method with f = f_i and j = W_i.\n\nNote that \"W\" is used to denote the same quantity in OrdinaryDiffEq.jl.","category":"section"},{"location":"test_problems/#Test-problems","page":"Test problems","title":"Test problems","text":"TODO: fill out","category":"section"},{"location":"algorithm_formulations/newtons_method/#Newton's-Method","page":"Newtons Method","title":"Newton's Method","text":"TODO: fill out","category":"section"},{"location":"algorithm_formulations/mrrk/#Multirate-Runge-Kutta","page":"Old MRRK Formulations","title":"Multirate Runge Kutta","text":"Given a problem with two components that operate at two rates:\n\nfracdudt = f_F(ut) + f_S(ut)\n\nwhere f_F is the fast component, and f_S is the slow component.\n\n[3] defines the following method.\n\nGiven an outer explicit Runge–Kutta scheme with tableau (abc)\n\nWe can define the stage values U^(i) = v_i(tau_i) as the solution to the inner ODE problem\n\nfracdv_idtau\n  = sum_j=1^i  fraca_ij - a_i-1jc_i - c_i-1  f_S (U^(j) tau_j)\n    + f_F(v_i tau)\nquad tau in tau_i-1 tau\n\nwhere tau_i = t + Delta t c_i, with initial condition v_i(tau_i-1) = U^(i-1). If c_i == c_i-1, we can treat it as a correction step:\n\nU^(i) = U^(i-1) + Delta t fracsum_j=1^i (a_ij - a_i-1j)c_i - c_i-1 f_S (U^(j) tau_i)\n\nThe final summation stage treating analogously to i=N+1, with a_N+1j = b_j and c_N+1 = 1.","category":"section"},{"location":"algorithm_formulations/mrrk/#Low-storage","page":"Old MRRK Formulations","title":"Low-storage","text":"If using a low-storage Runge–Kutta method is used as an outer solver, then this reduces to\n\nfracdv_idtau\n  =  fracB_i-1c_i - c_i-1 dU_S^(i-1)\n    + f_F(v_i tau)\nquad tau in tau_i-1 tau\n\nwhere\n\ndU_S^(i) = f_S(U^(i) tau_i) + A_i dU_S^(i-1)","category":"section"},{"location":"algorithm_formulations/mrrk/#Multirate-Infinitesimal-Step-(MIS)","page":"Old MRRK Formulations","title":"Multirate Infinitesimal Step (MIS)","text":"Multirate Infinitesimal Step (MIS) methods ([4], [5])\n\nbeginaligned\nv_i (0)\n  = u^n + sum_j=1^i-1 alpha_ij (U^(j) - u^n)\n\nfracdv_idtau\n  = sum_j=1^i-1 fracgamma_ijd_i Delta t (U^(j) - u^n)\n    + sum_j=1^i fracbeta_ijd_i f_S (U^(j) t + Delta t c_i)\n    + f_F(v_i t^n +  Delta t tilde c_i + fracc_i - tilde c_id_i tau)\nquad tau in 0 Delta t d_i\n\nU^(i) = v_i(Delta t d_i)\nendaligned\n\nThe method is defined in terms of the lower-triangular matrices alpha, beta and gamma, with d_i = sum_j beta_ij, c_i = (I - alpha - gamma)^-1 d and tilde c = alpha c.","category":"section"},{"location":"algorithm_formulations/mrrk/#Wicker-Skamarock","page":"Old MRRK Formulations","title":"Wicker Skamarock","text":"[6] and [7] define RK2 and RK3 multirate schemes:\n\nbeginaligned\nv_i (t) = u^n\n\nfracdv_idtau\n  = f_S (U^(i-1) t + Delta t c_i-1)\n    + f_F(v_i tau)\nquad tau in t t+ Delta t c_i \n\nU^(i) = v_i(t + Delta t c_i)\nendaligned\n\nwhich corresponds to an MIS method with alpha = gamma = 0 and beta = operatornamediag(c).","category":"section"},{"location":"dev/report_gen/#Verifying-Correctness","page":"Report generator","title":"Verifying Correctness","text":"The IMEXAlgorithm supports problems that specify any combination of the following: an implicit tendency T_imp!, an explicit tendency T_exp!, a limited tendency T_lim!, a function dss! that applies a direct stiffness summation, a function constrain_state! that applies additional state constraints, and a function lim! that applies a monotonicity-preserving limiter.","category":"section"},{"location":"dev/report_gen/#Convergence-without-a-Limiter","page":"Report generator","title":"Convergence without a Limiter","text":"In order to verify the correctness of our algorithms without a limiter, we compute their convergence orders for a variety of test cases. For each case, we estimate the convergence order of the algorithm over a range of stable timesteps, ensuring that the estimate computed_order ± order_uncertainty satisfies |computed_order - predicted_order| ≤ order_uncertainty and order_uncertainty ≤ predicted_order / 10. We also generate a plot that shows each algorithm's convergence as the timestep is reduced, along with plots that show the norms of each algorithm's solution and error over time (for some stable timestep). In addition, we verify that SSP algorithms produce the same results (up to floating-point roundoff error) when run in Unconstrained mode (at least, when run without a limiter).\n\nBy Godunov's theorem, the use of a monotonicity-preserving limiter reduces the convergence order of any algorithm to 1, so we do not include any test cases that use T_lim! and lim!.\n\nThe test cases we use for this analysis are:     - ark_analytic, which uses a nonlinear T_exp! and a linear T_imp!     - ark_analytic_sys and ark_onewaycouple_mri, which use a linear T_imp!     - ark_analytic_nonlin, which uses a nonlinear T_imp!     - 1d_heat_equation and 2d_heat_equation, which use a nonlinear T_exp! and dss!, where the spatial discretization is implemented using ClimaCore\n\nPlease see the Summaries section of our buildkite results, which has a comprehensive report.","category":"section"},{"location":"dev/report_gen/#Errors-with-a-Limiter","page":"Report generator","title":"Errors with a Limiter","text":"In order to verify the correctness of our algorithms with a limiter, we recreate Table 1 from \"Optimization-based limiters for the spectral element method\" by Guba et al. This involves running the horizontal_deformational_flow test case (from \"A standard test case suite for two-dimensional linear transport on the sphere\" by Lauritzen et al.) with and without a limiter, and also with and without hyperdiffusion. This test case uses a limited tendency T_lim! (which consists of advection and, optionally, hyperdiffusion), along with dss! and lim!. The spatial discretization is implemented using ClimaCore. Since this analysis is relatively expensive to run, we only check the results for SSP333 and ARS343. Note that it is possible to limit undershoots and overshoots to 0 (up to floating-point roundoff error) when using the SSP SSP333, but not when using the Unconstrained ARS343.\n\nPlease see the Summaries section of our buildkite results, which has a comprehensive report.","category":"section"},{"location":"dev/report_gen/#References","page":"Report generator","title":"References","text":"Example Programs for ARK ode (SUNDIALS)\n\"Optimization-based limiters for the spectral element method\" by Guba et al.\n\"A standard test case suite for two-dimensional linear transport on the sphere\" by Lauritzen et al.","category":"section"},{"location":"tutorials/diffusion/#A-full-example-on-how-to-use-ClimaTimesteppers-with-ClimaCore","page":"A full example on how to use ClimaTimesteppers with ClimaCore","title":"A full example on how to use ClimaTimesteppers with ClimaCore","text":"In this tutorial, we will solve a diffusion equation on a sphere using ClimaCore, and a mixed implicit-explicit solver in ClimaTimesteppers.\n\nFirst, we will set up the ClimaCore Spaces. We will define the implicit and explicit tendencies and Jacobian. Next, we will set up the ODE problem and solve it.","category":"section"},{"location":"tutorials/diffusion/#The-setup","page":"A full example on how to use ClimaTimesteppers with ClimaCore","title":"The setup","text":"In this example, we consider a 3D spherical shell. We set initial data up on the lower face of this shell, and we will see it diffuse horizontally and vertically. We will treat the horizontal diffusion explicitly and the vertical one implicitly.\n\nLet us start by importing the required pieces\n\nimport SciMLBase\nimport LinearAlgebra\nimport ClimaTimeSteppers\nimport ClimaCore\nimport Plots\nimport ClimaCore.MatrixFields: @name, ⋅, FieldMatrixWithSolver\n\nWe also define some units, mostly to make the code more explicit\n\nconst meters = meter = 1.0\nconst kilometers = kilometer = 1000meters\nconst seconds = second = 1.0\n\n1.0\n\nNow, we will set up the ClimaCore Spaces. There is some boilerplate involved.\n\nRadius and height of the spherical shell:\n\nradius = 6000kilometers\nheight = 1kilometers\n\n1000.0\n\nDetails of the computational grid:\n\nnumber_horizontal_elements = 10\nhorizontal_polynomial_order = 3\nnumber_vertical_elements = 10\n\n10\n\nWe prepare a face-centered vertical grid by first creating the Domain, then the Mesh, and finally the Space\n\nvertdomain = ClimaCore.Domains.IntervalDomain(\n    ClimaCore.Geometry.ZPoint(0kilometers),\n    ClimaCore.Geometry.ZPoint(height);\n    boundary_names = (:bottom, :top),\n);\nvertmesh = ClimaCore.Meshes.IntervalMesh(vertdomain; nelems = number_vertical_elements);\nvertspace = ClimaCore.Spaces.FaceFiniteDifferenceSpace(vertmesh);\n\nFor the horizontal grid, we create a 2D spectral element grid on a EquiangularCubedSphere mesh with Gauss-Lagrange-Lobatto quadrature points\n\nhorzdomain = ClimaCore.Domains.SphereDomain(radius);\nhorzmesh = ClimaCore.Meshes.EquiangularCubedSphere(horzdomain, number_horizontal_elements);\nhorztopology = ClimaCore.Topologies.Topology2D(ClimaCore.ClimaComms.context(), horzmesh);\nhorzquad = ClimaCore.Spaces.Quadratures.GLL{horizontal_polynomial_order + 1}();\nhorzspace = ClimaCore.Spaces.SpectralElementSpace2D(horztopology, horzquad);\n\nClimaComms.context() specify where the simulation should be run (ie, on CPU/GPU).\n\nFinally, we can combine vertspace and horzspace by extruding them (ie, taking their \"Cartesian product\")\n\nspace = ClimaCore.Spaces.ExtrudedFiniteDifferenceSpace(horzspace, vertspace);\n\nNow, we define the initial data. As initial data, we prepare Gaussian perturbation defined only on the lower vertical face. This Gaussian perturbation will diffuse horizontally and vertically\n\nσ = 15.0\n\n(; lat, long, z) = ClimaCore.Fields.coordinate_field(space);\nφ_gauss = @. exp(-(lat^2 + long^2) / σ^2) * (z < 0.005);\n\nNote how we multiplied by (z < 0.005) to ensure that the Gaussian perturbation is only on the lowest face.\n\nWhen working with ClimaCore, ClimaTimesteppers requires all the evolved variables to be packed in ClimaCore.FieldVectors. In this case, we only have one variable, which we will call my_var\n\nLet us pack this into a a FieldVector\n\nY₀ = ClimaCore.Fields.FieldVector(; my_var = copy(φ_gauss));\n\nWe copy φ_gauss because it it will be modified by the integrator.","category":"section"},{"location":"tutorials/diffusion/#The-equations-and-the-integrator","page":"A full example on how to use ClimaTimesteppers with ClimaCore","title":"The equations and the integrator","text":"The diffusion equation for u is partial_t u = K nabla^2 u, with K diffusivity. To solve this equation with ClimaTimesteppers, we have to provide the tendencies (ie, the right-hand-sides). We want to solve the diffusion equation horizontally and vertically. Horizontally, we will treat the evolution explicitly (currently, there is no other option for our spectral elements). On the other hand, we will solve the vertical diffusion implicitly. So, this problem has two tendencies, the explicit and the implicit ones.\n\nSo, let us start by defining the explicit tendency.\n\nA tendency for ClimaTimesteppers.jl is a function that generally takes four arguments (∂ₜY, Y, p, t). ∂ₜY is the right-hand side, which has to be modified by the function, Y is the current state, p is the cache (an optional collection of auxiliary variables) and t the time. Tendencies in ClimaTimesteppers.jl are in-place. In our case, we want the divergence of the gradient (the Laplacian) of my_var.\n\ndiverg = ClimaCore.Operators.WeakDivergence();\ngrad = ClimaCore.Operators.Gradient();\n\nK = 3.0\n\n3.0\n\nNotice how we picked WeakDivergence instead of normal divergence. We use the weak formulation of even derivatives (second-order, fourth-order, etc.) with the spectral element discretization because the outputs of derivative operators are not continuously differentiable. We also apply DSS to the outputs of weak derivatives before using them to compute higher-order odd derivatives.\n\nfunction T_exp!(∂ₜY, Y, _, _)\n    ∂ₜY.my_var .= K .* diverg.(grad.(Y.my_var))\n    return nothing\nend\n\nT_exp! (generic function with 1 method)\n\nWe do not specify boundary conditions here because we are on a sphere, where the only meaningful boundary conditions are periodic.\n\nNext, we move to the implicit tendency. This is much more involved to set up. First, we need again divergence and gradient. However, this time we want them for the vertical direction\n\ndiverg_vert = ClimaCore.Operators.DivergenceC2F(;\n    bottom = ClimaCore.Operators.SetDivergence(0.0),\n    top = ClimaCore.Operators.SetDivergence(0.0),\n);\ngrad_vert = ClimaCore.Operators.GradientF2C();\n\nWe choose DivergenceC2F and GradientF2C to implement the Laplacian. F2C and C2F stand for face-to-center and center-to-face. The choice is motivated so that we have a chain of operations that brings us back to faces. We are working with faces so that we can cleanly impose boundary conditions. The boundary condition we are setting here is null divergence at the top and bottom of the domain.\n\nfunction T_imp!(∂ₜY, Y, _, _)\n    ∂ₜY.my_var .= K .* diverg_vert.(grad_vert.(Y.my_var))\n    return nothing\nend\n\nT_imp! (generic function with 1 method)\n\nFor an implicit solver, we also need to provide the Jacobian of the implicit tendency, or precisely, the Wfact. Wfact is dt*γ*J - 1, where J is the Jacobian, dt the timestep, and γ a factor that enter the specific solver. In some places, you might find Wfact_t, meaning, Wfacttransformed. The relationship betweenWfactandWfacttisWfact = - dt*γ Wfactt`.\n\nThe Jacobian matrix has to be specified as a ClimaCore.MatrixFields.FieldMatrix. This matrix takes pairs of variable names name1 and name2 and returns the type for ∂name1\\∂name2. Given that we are working with gradient/divergence operations, our operations are tridiagonal, so have that\n\njacobian_matrix = ClimaCore.MatrixFields.FieldMatrix(\n    (@name(my_var), @name(my_var)) => similar(φ_gauss, ClimaCore.MatrixFields.TridiagonalMatrixRow{Float64}),\n);\n\nSimilarly, we define Wfact, as dtγ J - I.\n\ndiv_matrix = ClimaCore.MatrixFields.operator_matrix(diverg_vert)\ngrad_matrix = ClimaCore.MatrixFields.operator_matrix(grad_vert)\nfunction Wfact(W, Y, p, dtγ, t)\n    @. W.matrix[@name(my_var), @name(my_var)] = dtγ * div_matrix() ⋅ grad_matrix() - (LinearAlgebra.I,)\n    return nothing\nend\n\nWfact (generic function with 1 method)\n\nWith all of this, we are ready to define the implicit tendency. Implicit tendencies are SciMLBase.ODEFunctions and take in the actual tendency (similar to T_exp!), the Jacobian and Wfact:\n\nT_imp_wrapper! =\n    SciMLBase.ODEFunction(T_imp!; jac_prototype = FieldMatrixWithSolver(jacobian_matrix, Y₀), Wfact = Wfact);\n\nOn this type of spaces, we need to apply DSS to ensure continuity\n\nfunction dss!(state, p, t)\n    ClimaCore.Spaces.weighted_dss!(state.my_var)\nend\n\ndss! (generic function with 1 method)\n\nNow, we have all the pieces to set up the integrator\n\nt0 = 0seconds\nt_end = 500seconds\ndt = 5seconds\n\nprob = SciMLBase.ODEProblem(\n    ClimaTimeSteppers.ClimaODEFunction(; T_imp! = T_imp_wrapper!, T_exp!, dss!),\n    Y₀,\n    (t0, t_end),\n    nothing,\n);\n\nWe use SSPKnoth for this example\n\nalgo = ClimaTimeSteppers.RosenbrockAlgorithm(ClimaTimeSteppers.tableau(ClimaTimeSteppers.SSPKnoth()));\n\nAnd here is the integrator, where we set saveat = t0:dt:t_end to save a snapshot of the solution at every timestep.\n\nintegrator = SciMLBase.init(prob, algo; dt, saveat = t0:dt:t_end);\n\n# Solution and visualization\n\nTo visualize the solution, we use ClimaCore.Remapper and Plots\n\nLet us a prepare a convenience function that remaps a ClimaCore.Fields onto a 2D Cartesian grid at a target z.\n\nfunction remap(; target_z = 0.0, integrator = integrator)\n    longpts = range(-180.0, 180.0, 180)\n    latpts = range(-90.0, 90.0, 90)\n    hcoords = [ClimaCore.Geometry.LatLongPoint(lat, long) for long in longpts, lat in latpts]\n    zcoords = [ClimaCore.Geometry.ZPoint(target_z)]\n    field = integrator.u.my_var\n    space = axes(field)\n    remapper = ClimaCore.Remapping.Remapper(space, hcoords, zcoords)\n    return ClimaCore.Remapping.interpolate(remapper, field)[:, :, begin]\nend\n\nremap (generic function with 1 method)\n\nFirst, let us have a look at the surface, where we have the initial Gaussian perturbation\n\nPlots.heatmap(remap());\nPlots.savefig(\"diff-hm1.png\")\n\n\"/home/runner/work/ClimaTimeSteppers.jl/ClimaTimeSteppers.jl/docs/src/tutorials/diff-hm1.png\"\n\n(Image: )\n\nNow, let us double check that it is empty at higher elevation\n\nPlots.heatmap(remap(; target_z = 0.1kilometers));\nPlots.savefig(\"diff-hm2.png\")\n\n\"/home/runner/work/ClimaTimeSteppers.jl/ClimaTimeSteppers.jl/docs/src/tutorials/diff-hm2.png\"\n\n(Image: )\n\nThe extrema for my_var at the beginning of the simulation are\n\nextrema(integrator.u)\n\n(0.0, 1.0)\n\nLet us focus on the surface level\n\nextrema(ClimaCore.Fields.level(integrator.u.my_var, ClimaCore.Utilities.PlusHalf(0)))\n\n(4.766380244828023e-78, 1.0)\n\nAnd the first level\n\nextrema(ClimaCore.Fields.level(integrator.u.my_var, ClimaCore.Utilities.PlusHalf(1)))\n\n(0.0, 0.0)\n\nLet us solve the equation\n\nSciMLBase.solve!(integrator);\n\nNow, the extreme for my_var will have decreased, due to diffusion\n\nextrema(integrator.u)\n\n(-6.7618769531562785e-25, 0.999999997550737)\n\nLet us focus on the surface level\n\nextrema(ClimaCore.Fields.level(integrator.u.my_var, ClimaCore.Utilities.PlusHalf(0)))\n\n(-6.7618769531562785e-25, 0.999999997550737)\n\nAnd the first level\n\nextrema(ClimaCore.Fields.level(integrator.u.my_var, ClimaCore.Utilities.PlusHalf(1)))\n\n(-8.793224768217326e-26, 0.1300418758764668)\n\nAnd we will see some development on the layers that did not have data before\n\nPlots.heatmap(remap(; target_z = 0.1kilometers))\nPlots.savefig(\"diff-hm3.png\")\n\n\"/home/runner/work/ClimaTimeSteppers.jl/ClimaTimeSteppers.jl/docs/src/tutorials/diff-hm3.png\"\n\n(Image: )\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"api/ode_solvers/#ODE-Solvers","page":"ODE Solvers","title":"ODE Solvers","text":"","category":"section"},{"location":"api/ode_solvers/#Interface","page":"ODE Solvers","title":"Interface","text":"","category":"section"},{"location":"api/ode_solvers/#IMEX-Algorithm-Names","page":"ODE Solvers","title":"IMEX Algorithm Names","text":"","category":"section"},{"location":"api/ode_solvers/#Explicit-Algorithm-Names","page":"ODE Solvers","title":"Explicit Algorithm Names","text":"","category":"section"},{"location":"api/ode_solvers/#Old-LSRK-Interface","page":"ODE Solvers","title":"Old LSRK Interface","text":"","category":"section"},{"location":"api/ode_solvers/#Old-Multirate-Interface","page":"ODE Solvers","title":"Old Multirate Interface","text":"","category":"section"},{"location":"api/ode_solvers/#ClimaTimeSteppers.ClimaODEFunction","page":"ODE Solvers","title":"ClimaTimeSteppers.ClimaODEFunction","text":"ClimaODEFunction(; T_imp!, [dss!], [constrain_state!], [cache!], [cache_imp!])\nClimaODEFunction(; T_exp!, T_lim!, [T_imp!], [lim!], [dss!], [constrain_state!], [cache!], [cache_imp!])\nClimaODEFunction(; T_exp_lim!, [T_imp!], [lim!], [dss!], [constrain_state!], [cache!], [cache_imp!])\n\nContainer for all functions used to advance through a timestep:\n\nT_imp!(T_imp, u, p, t): sets the implicit tendency\nT_exp!(T_exp, u, p, t): sets the component of the explicit tendency that   is not passed through the limiter\nT_lim!(T_lim, u, p, t): sets the component of the explicit tendency that   is passed through the limiter\nT_exp_lim!(T_exp, T_lim, u, p, t): fused alternative to the separate   functions T_exp! and T_lim!\nlim!(u, p, t, u_ref): applies the limiter to every state u that has   been incremented from u_ref by the explicit tendency component T_lim!\ndss!(u, p, t): applies direct stiffness summation to every state u,\nconstrain_state!(u, p, t): applies a constraint to every state u,   except for intermediate states generated within the implicit solver\ncache!(u, p, t): updates the cache p to reflect the state u before   the first timestep and on every subsequent timestepping stage\ncache_imp!(u, p, t): updates the components of the cache p that are   required to evaluate T_imp! and its Jacobian within the implicit solver\n\nBy default, lim!, dss!, constrain_state!, and cache! all do nothing, and cache_imp! is identical to cache!. Any of the tendency functions can be set to nothing in order to avoid corresponding allocations in the integrator.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.AbstractAlgorithmConstraint","page":"ODE Solvers","title":"ClimaTimeSteppers.AbstractAlgorithmConstraint","text":"AbstractAlgorithmConstraint\n\nA mechanism for constraining which operations can be performed by an algorithm for solving ODEs.\n\nFor example, an unconstrained algorithm might compute a Runge-Kutta stage by taking linear combinations of tendencies; i.e., by adding quantities of the form dt * tendency(state). On the other hand, a \"strong stability preserving\" algorithm can only take linear combinations of \"incremented states\"; i.e., it only adds quantities of the form state + dt * coefficient * tendency(state).\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.Unconstrained","page":"ODE Solvers","title":"ClimaTimeSteppers.Unconstrained","text":"Unconstrained\n\nIndicates that an algorithm may perform any supported operations.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.SSP","page":"ODE Solvers","title":"ClimaTimeSteppers.SSP","text":"SSP\n\nIndicates that an algorithm must be \"strong stability preserving\", which makes it easier to guarantee that the algorithm will preserve monotonicity properties satisfied by the initial state. For example, this ensures that the algorithm will be able to use limiters in a mathematically consistent way.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMEXTableau","page":"ODE Solvers","title":"ClimaTimeSteppers.IMEXTableau","text":"IMEXTableau(; a_exp, b_exp, c_exp, a_imp, b_imp, c_imp)\n\nA wrapper for an IMEX Butcher tableau (or, more accurately, a pair of Butcher tableaus, one for explicit tendencies and the other for implicit tendencies). Only a_exp and a_imp are required arguments; the default values for b_exp and b_imp assume that the algorithm is FSAL (first same as last), and the default values for c_exp and c_imp assume that it is internally consistent.\n\nThe explicit tableau must be strictly lower triangular, and the implicit tableau must be lower triangular (only DIRK algorithms are currently supported).\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMEXAlgorithm","page":"ODE Solvers","title":"ClimaTimeSteppers.IMEXAlgorithm","text":"IMEXAlgorithm(tableau, newtons_method, [constraint])\nIMEXAlgorithm(name, newtons_method, [constraint])\n\nConstructs an IMEX algorithm for solving ODEs, with an optional name and constraint. The first constructor accepts any IMEXTableau and an optional constraint, leaving the algorithm unnamed. The second constructor automatically determines the tableau and the default constraint from the algorithm name, which must be an IMEXARKAlgorithmName.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.ExplicitTableau","page":"ODE Solvers","title":"ClimaTimeSteppers.ExplicitTableau","text":"ExplicitTableau(; a, b, c)\n\nA wrapper for an explicit Butcher tableau. Only a is a required argument; the default value for b assumes that the algorithm is FSAL (first same as last), and the default value for c assumes that it is internally consistent. The matrix a must be strictly lower triangular.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.ExplicitAlgorithm","page":"ODE Solvers","title":"ClimaTimeSteppers.ExplicitAlgorithm","text":"ExplicitAlgorithm(tableau, [constraint])\nExplicitAlgorithm(name, [constraint])\n\nConstructs an explicit algorithm for solving ODEs, with an optional name and constraint. The first constructor accepts any ExplicitTableau and an optional constraint, leaving the algorithm unnamed. The second constructor automatically determines the tableau and the default constraint from the algorithm name, which must be an ERKAlgorithmName.\n\nNote that using an ExplicitAlgorithm is merely a shorthand for using an IMEXAlgorithm with the same tableau for explicit and implicit tendencies (and without Newton's method).\n\n\n\n\n\n","category":"function"},{"location":"api/ode_solvers/#ClimaTimeSteppers.ARS111","page":"ODE Solvers","title":"ClimaTimeSteppers.ARS111","text":"ARS111\n\nAn IMEX ARK algorithm from [8], section 2, with 1 implicit stage, 1 explicit stage and 1st order accuracy. Also called IMEX Euler or forward-backward Euler; equivalent to OrdinaryDiffEq.IMEXEuler.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.ARS121","page":"ODE Solvers","title":"ClimaTimeSteppers.ARS121","text":"ARS121\n\nAn IMEX ARK algorithm from [8], section 2, with 1 implicit stage, 2 explicit stages, and 1st order accuracy. Also called IMEX Euler or forward-backward Euler; equivalent to OrdinaryDiffEq.IMEXEulerARK.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.ARS122","page":"ODE Solvers","title":"ClimaTimeSteppers.ARS122","text":"ARS122\n\nAn IMEX ARK algorithm from [8], section 2, with 1 implicit stage, 2 explicit stages, and 2nd order accuracy. Also called IMEX midpoint.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.ARS233","page":"ODE Solvers","title":"ClimaTimeSteppers.ARS233","text":"ARS233\n\nAn IMEX ARK algorithm from [8], section 2, with 2 implicit stages, 3 explicit stages, and 3rd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.ARS232","page":"ODE Solvers","title":"ClimaTimeSteppers.ARS232","text":"ARS232\n\nAn IMEX ARK algorithm from [8], section 2, with 2 implicit stages, 3 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.ARS222","page":"ODE Solvers","title":"ClimaTimeSteppers.ARS222","text":"ARS222\n\nAn IMEX ARK algorithm from [8], section 2, with 2 implicit stages, 2 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.ARS343","page":"ODE Solvers","title":"ClimaTimeSteppers.ARS343","text":"ARS343\n\nAn IMEX ARK algorithm from [8], section 2, with 3 implicit stages, 4 explicit stages, and 3rd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.ARS443","page":"ODE Solvers","title":"ClimaTimeSteppers.ARS443","text":"ARS443\n\nAn IMEX ARK algorithm from [8], section 2, with 4 implicit stages, 4 explicit stages, and 3rd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMKG232a","page":"ODE Solvers","title":"ClimaTimeSteppers.IMKG232a","text":"IMKG232a\n\nAn IMEX ARK algorithm from [9], Table 3, with 2 implicit stages, 3 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMKG232b","page":"ODE Solvers","title":"ClimaTimeSteppers.IMKG232b","text":"IMKG232b\n\nAn IMEX ARK algorithm from [9], Table 3, with 2 implicit stages, 3 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMKG242a","page":"ODE Solvers","title":"ClimaTimeSteppers.IMKG242a","text":"IMKG242a\n\nAn IMEX ARK algorithm from [9], Table 3, with 2 implicit stages, 4 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMKG242b","page":"ODE Solvers","title":"ClimaTimeSteppers.IMKG242b","text":"IMKG242b\n\nAn IMEX ARK algorithm from [9], Table 3, with 2 implicit stages, 4 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMKG243a","page":"ODE Solvers","title":"ClimaTimeSteppers.IMKG243a","text":"IMKG243a\n\nAn IMEX ARK algorithm from [9], Table 3, with 3 implicit stages, 4 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMKG252a","page":"ODE Solvers","title":"ClimaTimeSteppers.IMKG252a","text":"IMKG252a\n\nAn IMEX ARK algorithm from [9], Table 3, with 2 implicit stages, 5 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMKG252b","page":"ODE Solvers","title":"ClimaTimeSteppers.IMKG252b","text":"IMKG252b\n\nAn IMEX ARK algorithm from [9], Table 3, with 2 implicit stages, 5 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMKG253a","page":"ODE Solvers","title":"ClimaTimeSteppers.IMKG253a","text":"IMKG253a\n\nAn IMEX ARK algorithm from [9], Table 3, with 3 implicit stages, 5 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMKG253b","page":"ODE Solvers","title":"ClimaTimeSteppers.IMKG253b","text":"IMKG253b\n\nAn IMEX ARK algorithm from [9], Table 3, with 3 implicit stages, 5 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMKG254a","page":"ODE Solvers","title":"ClimaTimeSteppers.IMKG254a","text":"IMKG254a\n\nAn IMEX ARK algorithm from [9], Table 3, with 4 implicit stages, 5 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMKG254b","page":"ODE Solvers","title":"ClimaTimeSteppers.IMKG254b","text":"IMKG254b\n\nAn IMEX ARK algorithm from [9], Table 3, with 4 implicit stages, 5 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMKG254c","page":"ODE Solvers","title":"ClimaTimeSteppers.IMKG254c","text":"IMKG254c\n\nAn IMEX ARK algorithm from [9], Table 3, with 4 implicit stages, 5 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMKG342a","page":"ODE Solvers","title":"ClimaTimeSteppers.IMKG342a","text":"IMKG342a\n\nAn IMEX ARK algorithm from [9], Table 4, with 2 implicit stages, 4 explicit stages, and 3rd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.IMKG343a","page":"ODE Solvers","title":"ClimaTimeSteppers.IMKG343a","text":"IMKG343a\n\nAn IMEX ARK algorithm from [9], Table 4, with 3 implicit stages, 4 explicit stages, and 3rd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.SSP222","page":"ODE Solvers","title":"ClimaTimeSteppers.SSP222","text":"SSP222\n\nAn IMEX SSPRK algorithm from [10], with 2 implicit stages, 2 explicit stages, and 2nd order accuracy. Also called SSP2(222) in [11].\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.SSP322","page":"ODE Solvers","title":"ClimaTimeSteppers.SSP322","text":"SSP322\n\nAn IMEX SSPRK algorithm from [10], with 3 implicit stages, 2 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.SSP332","page":"ODE Solvers","title":"ClimaTimeSteppers.SSP332","text":"SSP332\n\nAn IMEX SSPRK algorithm from [10], with 3 implicit stages, 3 explicit stages, and 2nd order accuracy. Also called SSP2(332)a in [11].\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.SSP333","page":"ODE Solvers","title":"ClimaTimeSteppers.SSP333","text":"SSP333(; β = 1/2 + √3/6)\n\nFamily of IMEX SSPRK algorithms parametrized by the value β from [12], Section 3.2, with 3 implicit stages, 3 explicit stages, and 3rd order accuracy. The default value of β results in an SDIRK algorithm, which is also called SSP3(333)c in [11].\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.SSP433","page":"ODE Solvers","title":"ClimaTimeSteppers.SSP433","text":"SSP433\n\nAn IMEX SSPRK algorithm from [10], with 4 implicit stages, 3 explicit stages, and 3rd order accuracy. Also called SSP3(433) in [11].\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.DBM453","page":"ODE Solvers","title":"ClimaTimeSteppers.DBM453","text":"DBM453\n\nAn IMEX ARK algorithm from [13], Appendix A, with 4 implicit stages, 5 explicit stages, and 3rd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.HOMMEM1","page":"ODE Solvers","title":"ClimaTimeSteppers.HOMMEM1","text":"HOMMEM1\n\nAn IMEX ARK algorithm from [14], section 4.1, with 5 implicit stages, 6 explicit stages, and 2nd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.ARK2GKC","page":"ODE Solvers","title":"ClimaTimeSteppers.ARK2GKC","text":"ARK2GKC(; paper_version = false)\n\nAn IMEX ARK algorithm from [15] with 2 implicit stages, 3 explicit stages, and 2nd order accuracy. If paper_version = true, the algorithm uses coefficients from the paper. Otherwise, it uses coefficients that make it more stable but less accurate.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.ARK437L2SA1","page":"ODE Solvers","title":"ClimaTimeSteppers.ARK437L2SA1","text":"ARK437L2SA1\n\nAn IMEX ARK algorithm from [16], Table 8, with 6 implicit stages, 7 explicit stages, and 4th order accuracy. Written as ARK4(3)7L[2]SA₁ in the paper.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.ARK548L2SA2","page":"ODE Solvers","title":"ClimaTimeSteppers.ARK548L2SA2","text":"ARK548L2SA2\n\nAn IMEX ARK algorithm from [16], Table 8, with 7 implicit stages, 8 explicit stages, and 5th order accuracy. Written as ARK5(4)8L[2]SA₂ in the paper.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.SSPKnoth","page":"ODE Solvers","title":"ClimaTimeSteppers.SSPKnoth","text":"SSPKnoth\n\nSSPKnoth is a second-order Rosenbrock method developed by Oswald Knoth.\n\nThe coefficients are the same as in CGDycore.jl, except that for C we add the diagonal elements too. Note, however, that the elements on the diagonal of C do not really matter because C is only used in its lower triangular part. We add them mostly to match literature on the subject\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.SSP22Heuns","page":"ODE Solvers","title":"ClimaTimeSteppers.SSP22Heuns","text":"SSP22Heuns\n\nAn SSPRK algorithm from [17], with 2 stages and 2nd order accuracy. Also called Heun's method ([18]).\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.SSP33ShuOsher","page":"ODE Solvers","title":"ClimaTimeSteppers.SSP33ShuOsher","text":"SSP33ShuOsher\n\nAn SSPRK algorithm from [17], with 3 stages and 3rd order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.RK4","page":"ODE Solvers","title":"ClimaTimeSteppers.RK4","text":"RK4\n\nThe RK4 algorithm from [19], a Runge-Kutta method with 4 stages and 4th order accuracy.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.ForwardEulerODEFunction","page":"ODE Solvers","title":"ClimaTimeSteppers.ForwardEulerODEFunction","text":"ForwardEulerODEFunction(f; jac_prototype, Wfact, tgrad)\n\nAn ODE function wrapper where f(un, u, p, t, dt) provides a forward Euler update\n\nun .= u .+ dt * f(u, p, t)\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.LowStorageRungeKutta2N","page":"ODE Solvers","title":"ClimaTimeSteppers.LowStorageRungeKutta2N","text":"LowStorageRungeKutta2N <: DistributedODEAlgorithm\n\nA class of low-storage Runge-Kutta algorithms, which use only one additional copy of the state vector u (often referred to as 2N schemes).\n\nThe available implementations are:\n\nLSRKEulerMethod\nLSRK54CarpenterKennedy\nLSRK144NiegemannDiehlBusch\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.LSRK54CarpenterKennedy","page":"ODE Solvers","title":"ClimaTimeSteppers.LSRK54CarpenterKennedy","text":"LSRK54CarpenterKennedy()\n\nThe 4th-order, 5-stage [LowStorageRungeKutta2N])(ref) scheme from Solution 3 of [20].\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.LSRK144NiegemannDiehlBusch","page":"ODE Solvers","title":"ClimaTimeSteppers.LSRK144NiegemannDiehlBusch","text":"LSRK144NiegemannDiehlBusch()\n\nThe 4th-order, 14-stage, [LowStorageRungeKutta2N])(ref) scheme of [21] with optimized stability region\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.LSRKEulerMethod","page":"ODE Solvers","title":"ClimaTimeSteppers.LSRKEulerMethod","text":"LSRKEulerMethod()\n\nAn implementation of explicit Euler method using LowStorageRungeKutta2N infrastructure. This is mainly for debugging.\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.Multirate","page":"ODE Solvers","title":"ClimaTimeSteppers.Multirate","text":"Multirate(fast, slow)\n\nA multirate Runge–Kutta scheme, combining fast and slow algorithms\n\nslow can be any algorithm providing methods for the following functions\n\ninit_inner(prob, outercache, dt)\nupdate_inner!(innerinteg, outercache, f_slow, u, p, t, dt, stage)\n\nAlgorithms which currently support this are:\n\nLowStorageRungeKutta2N\nMultirateInfinitesimalStep\nWickerSkamarockRungeKutta\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.MultirateInfinitesimalStep","page":"ODE Solvers","title":"ClimaTimeSteppers.MultirateInfinitesimalStep","text":"MultirateInfinitesimalStep\n\nMultirate Infinitesimal Step (MIS) methods of [4] and [5].\n\nThe available implementations are:\n\nMIS2\nMIS3C\nMIS4\nMIS4a\nTVDMISA\nTVDMISB\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.MIS2","page":"ODE Solvers","title":"ClimaTimeSteppers.MIS2","text":"MIS2()\n\nThe MIS2 Multirate Infinitesimal Step (MIS) method of [5].\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.MIS3C","page":"ODE Solvers","title":"ClimaTimeSteppers.MIS3C","text":"MIS3C()\n\nThe MIS3C Multirate Infinitesimal Step (MIS) method of [5].\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.MIS4","page":"ODE Solvers","title":"ClimaTimeSteppers.MIS4","text":"MIS4()\n\nThe MIS4 Multirate Infinitesimal Step (MIS) method of [5].\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.MIS4a","page":"ODE Solvers","title":"ClimaTimeSteppers.MIS4a","text":"MIS4a()\n\nThe MIS4a Multirate Infinitesimal Step (MIS) method of [5].\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.TVDMISA","page":"ODE Solvers","title":"ClimaTimeSteppers.TVDMISA","text":"TVDMISA()\n\nThe TVDMISA Total Variation Diminishing (TVD) Multirate Infinitesimal Step (MIS) method of [5].\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.TVDMISB","page":"ODE Solvers","title":"ClimaTimeSteppers.TVDMISB","text":"TVDMISB()\n\nThe TVDMISB Total Variation Diminishing (TVD) Multirate Infinitesimal Step (MIS) method of [5].\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.WickerSkamarockRungeKutta","page":"ODE Solvers","title":"ClimaTimeSteppers.WickerSkamarockRungeKutta","text":"WickerSkamarockRungeKutta <: DistributedODEAlgorithm\n\nClass of multirate algorithms developed in [6] and [7], which can be used as slow methods in Multirate.\n\nThese require two additional copies of the state vector u.\n\nAvailable implementations are:\n\nWSRK2\nWSRK3\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.WSRK2","page":"ODE Solvers","title":"ClimaTimeSteppers.WSRK2","text":"WSRK2()\n\nThe 2 stage, 2nd order RK2 scheme of [6].\n\n\n\n\n\n","category":"type"},{"location":"api/ode_solvers/#ClimaTimeSteppers.WSRK3","page":"ODE Solvers","title":"ClimaTimeSteppers.WSRK3","text":"WSRK3()\n\nThe 3 stage, 2nd order (3rd order for linear problems) RK3 scheme of [7].\n\n\n\n\n\n","category":"type"},{"location":"dev/types/#Types","page":"Types","title":"Types","text":"In this section, we print out the type hierarchies of some classes via code snippets.","category":"section"},{"location":"dev/types/#Algorithms","page":"Types","title":"Algorithms","text":"import AbstractTrees as AT\nimport InteractiveUtils as IU\nimport ClimaTimeSteppers as CTS\nAT.children(x::Type) = IU.subtypes(x)\nAT.print_tree(CTS.DistributedODEAlgorithm)","category":"section"},{"location":"dev/types/#Tableaus","page":"Types","title":"Tableaus","text":"import AbstractTrees as AT\nimport InteractiveUtils as IU\nimport ClimaTimeSteppers as CTS\nAT.children(x::Type) = IU.subtypes(x)\nAT.print_tree(CTS.AbstractAlgorithmName)","category":"section"},{"location":"test_problems/diffusion_2d/#2D-diffusion-problem","page":"2D diffusion problem","title":"2D diffusion problem","text":"TODO: cleanup\n\nDue to conservation of (heat) energy, we know that\n    c * ρ * ∂u/∂t = k * Δu + q,\nwhere u is the temperature (K), c is the specific heat capacity (J/kg/K), ρ is\nthe density (kg/m^3), k is the thermal conductivity (W/m/K), and q is the rate\nat which heat energy is added/removed (W/m^3).\nWe can simplify this PDE to\n    ∂u/∂t = α * Δu + f,\nwhere α = k/c/ρ is the thermal diffusivity (m^2/s) and f = q/c/ρ is the rate at\nwhich heat energy is added/removed in units of temperature (K/s).\nWe will solve this PDE for u(x, y, t) over the domain (x, y) ∈ [0, l] × [0, l]\nand t ≥ 0. For simplicity, we will use periodic boundary conditions:\n    u(0, y, t) = u(l, y, t),\n    u(x, 0, t) = u(x, l, t),\n    ∇u(0, y, t) = ∇u(l, y, t), and\n    ∇u(x, 0, t) = ∇u(x, l, t).\nAlso, for simplicity, we will assume that α is a constant.\nSuppose that\n    f = 0 and\n    u(x, y, 0) = u₀(x, y).\nThe general solution to the PDE (obtained with separation of variables) is then\n    u(x, y, t) =\n        ∑_{n = 0}^∞ ∑_{m = 0}^∞ exp(-λₙₘ * t) * (\n            φᶜᶜₙₘ(x, y) * ⟨φᶜᶜₙₘ(x, y), u₀(x, y)⟩ / ⟨φᶜᶜₙₘ(x, y), φᶜᶜₙₘ(x, y)⟩ +\n            φᶜˢₙₘ(x, y) * ⟨φᶜˢₙₘ(x, y), u₀(x, y)⟩ / ⟨φᶜˢₙₘ(x, y), φᶜˢₙₘ(x, y)⟩ +\n            φˢᶜₙₘ(x, y) * ⟨φˢᶜₙₘ(x, y), u₀(x, y)⟩ / ⟨φˢᶜₙₘ(x, y), φˢᶜₙₘ(x, y)⟩ +\n            φˢˢₙₘ(x, y) * ⟨φˢˢₙₘ(x, y), u₀(x, y)⟩ / ⟨φˢˢₙₘ(x, y), φˢˢₙₘ(x, y)⟩\n        ), where\n    φᶜᶜₙₘ(x, y) = cos(2 * π * n * x / l) * cos(2 * π * m * y / l),\n    φᶜˢₙₘ(x, y) = cos(2 * π * n * x / l) * sin(2 * π * m * y / l),\n    φˢᶜₙₘ(x, y) = sin(2 * π * n * x / l) * cos(2 * π * m * y / l),\n    φˢˢₙₘ(x, y) = sin(2 * π * n * x / l) * sin(2 * π * m * y / l), and\n    λₙₘ = (2 * π / l)^2 * (n^2 + m^2) * α.\nNote that the inner product of two functions g(x, y) and h(x, y) is defined as\n    ⟨g(x, y), h(x, y)⟩ = ∫_0^l ∫_0^l g(x, y) h(x, y) dx dy.\nWhen n = 0 or m = 0, some of the inner product denominators above are 0, but\nthis doesn't actually matter because the corresponding numerators are also 0 and\nthose terms can just be ignored.\nSo, the solution operator for the homogeneous PDE (with f = 0) is\n    F(u₀)(x, y, t) =\n        ∑_{n = 0}^∞ ∑_{m = 0}^∞ exp(-λₙₘ * t) * (\n            φᶜᶜₙₘ(x, y) * ⟨φᶜᶜₙₘ(x, y), u₀(x, y)⟩ / ⟨φᶜᶜₙₘ(x, y), φᶜᶜₙₘ(x, y)⟩ +\n            φᶜˢₙₘ(x, y) * ⟨φᶜˢₙₘ(x, y), u₀(x, y)⟩ / ⟨φᶜˢₙₘ(x, y), φᶜˢₙₘ(x, y)⟩ +\n            φˢᶜₙₘ(x, y) * ⟨φˢᶜₙₘ(x, y), u₀(x, y)⟩ / ⟨φˢᶜₙₘ(x, y), φˢᶜₙₘ(x, y)⟩ +\n            φˢˢₙₘ(x, y) * ⟨φˢˢₙₘ(x, y), u₀(x, y)⟩ / ⟨φˢˢₙₘ(x, y), φˢˢₙₘ(x, y)⟩\n        ).\nWe can express the initial condition of our PDE using in terms of its Fourier\nseries as\n    u₀(x, y) =\n        ∑_{n = 0}^∞ ∑_{m = 0}^∞ (\n            u₀ᶜᶜₙₘ * φᶜᶜₙₘ(x, y) +\n            u₀ᶜˢₙₘ * φᶜˢₙₘ(x, y) +\n            u₀ˢᶜₙₘ * φˢᶜₙₘ(x, y) +\n            u₀ˢˢₙₘ * φˢˢₙₘ(x, y)\n        ).\nNow, consider the inhomogeneous PDE for which\n    f(x, y, t) = f̂(t)(x, y) =\n        ∑_{n = 0}^∞ ∑_{m = 0}^∞ exp(-λ′ₙₘ * t) * (\n            f₀ᶜᶜₙₘ * φᶜᶜₙₘ(x, y) +\n            f₀ᶜˢₙₘ * φᶜˢₙₘ(x, y) +\n            f₀ˢᶜₙₘ * φˢᶜₙₘ(x, y) +\n            f₀ˢˢₙₘ * φˢˢₙₘ(x, y)\n        ).\n(Note that, if we allow the time-dependence to have a form that is not\nexponential, the resulting solution will contain non-elementary integrals.)\nDuhamel's formula tells us that the solution to the inhomogeneous PDE is\n    u(x, y, t) = F(u₀)(x, y, t) + ∫_0^t F(f̂(τ))(x, y, t - τ) dτ =\n        ∑_{n = 0}^∞ ∑_{m = 0}^∞ exp(-λₙₘ * t) * (\n            u₀ᶜᶜₙₘ * φᶜᶜₙₘ(x, y) +\n            u₀ᶜˢₙₘ * φᶜˢₙₘ(x, y) +\n            u₀ˢᶜₙₘ * φˢᶜₙₘ(x, y) +\n            u₀ˢˢₙₘ * φˢˢₙₘ(x, y)\n        ) +\n        ∫_0^t ∑_{n = 0}^∞ ∑_{m = 0}^∞ (\n            exp(-λ′ₙₘ * τ - λₙₘ * (t - τ)) * (\n                f₀ᶜᶜₙₘ * φᶜᶜₙₘ(x, y) +\n                f₀ᶜˢₙₘ * φᶜˢₙₘ(x, y) +\n                f₀ˢᶜₙₘ * φˢᶜₙₘ(x, y) +\n                f₀ˢˢₙₘ * φˢˢₙₘ(x, y)\n            )\n        ) dτ =\n        ∑_{n = 0}^∞ ∑_{m = 0}^∞ exp(-λₙₘ * t) * (\n            u₀ᶜᶜₙₘ * φᶜᶜₙₘ(x, y) +\n            u₀ᶜˢₙₘ * φᶜˢₙₘ(x, y) +\n            u₀ˢᶜₙₘ * φˢᶜₙₘ(x, y) +\n            u₀ˢˢₙₘ * φˢˢₙₘ(x, y)\n        ) +\n        ∑_{n = 0}^∞ ∑_{m = 0}^∞ (\n            exp(-λₙₘ * t) / (λₙₘ - λ′ₙₘ) * (exp((λₙₘ - λ′ₙₘ) * t) - 1)\n        ) * (\n            f₀ᶜᶜₙₘ * φᶜᶜₙₘ(x, y) +\n            f₀ᶜˢₙₘ * φᶜˢₙₘ(x, y) +\n            f₀ˢᶜₙₘ * φˢᶜₙₘ(x, y) +\n            f₀ˢˢₙₘ * φˢˢₙₘ(x, y)\n        ).\nIf we let λ′ₙₘ = λₙₘ + Δλₙₘ, this simplifies to\n    u(x, y, t) =\n        ∑_{n = 0}^∞ ∑_{m = 0}^∞ exp(-λₙₘ * t) * (\n            u₀ᶜᶜₙₘ * φᶜᶜₙₘ(x, y) +\n            u₀ᶜˢₙₘ * φᶜˢₙₘ(x, y) +\n            u₀ˢᶜₙₘ * φˢᶜₙₘ(x, y) +\n            u₀ˢˢₙₘ * φˢˢₙₘ(x, y)\n        ) +\n        ∑_{n = 0}^∞ ∑_{m = 0}^∞ exp(-λₙₘ * t) / Δλₙₘ * (1 - exp(-Δλₙₘ * t)) * (\n            f₀ᶜᶜₙₘ * φᶜᶜₙₘ(x, y) +\n            f₀ᶜˢₙₘ * φᶜˢₙₘ(x, y) +\n            f₀ˢᶜₙₘ * φˢᶜₙₘ(x, y) +\n            f₀ˢˢₙₘ * φˢˢₙₘ(x, y)\n        ).\nFor the test case below, we will only use the φˢˢₙₘ eigenfunction for specific\nvalues of n and m. In other words, we will pick some constants n, m, u₀, f₀, and\nΔλ, and we will set\n    u(x, y, 0) = u₀ * φˢˢₙₘ(x, y) and\n    f(x, y, t) = f₀ * exp(-(λₙₘ + Δλ) * t) * φˢˢₙₘ(x, y).\nWe should then end up with the solution\n    u(x, y, t) =\n        (u₀ + f₀ / Δλ * (1 - exp(-Δλ * t))) * exp(-λₙₘ * t) * φˢˢₙₘ(x, y).\nIn addition, we will use nondimensionalization to replace our variables with\n    x̂ = x / l,\n    ŷ = y / l,\n    t̂ = t / (l^2 / α),\n    û(x̂, ŷ, t̂) = u(x, y, t) / u₀,\n    f̂(x̂, ŷ, t̂) = f(x, y, t) / (u₀ / (l^2 / α)).\nNote that this converts the time t into the \"Fourier number\" α * t / l^2.\nWe will then define the nondimensionalized constants\n    λ̂ₙₘ = λₙₘ * l^2 / α = (2 * π)^2 * (n^2 + m^2),\n    Δλ̂ = Δλ * l^2 / α, and\n    f̂₀ = f₀ / (u₀ / (l^2 / α))\nWe will also rewrite the eigenfunction in terms of the new variables as\n    φ̂ˢˢₙₘ(x̂, ŷ) = φˢˢₙₘ(x̂ * l, ŷ * l) = sin(2 * π * n * x̂) * sin(2 * π * m * ŷ).\nOur simplified PDE then becomes\n    ∂û/∂t̂ = Δû + f̂, where\n    û(x̂, ŷ, 0) = φ̂ˢˢₙₘ(x̂, ŷ) and\n    f̂(x̂, ŷ, t̂) = f̂₀ * exp(-(λ̂ₙₘ + Δλ̂) * t̂) * φ̂ˢˢₙₘ(x̂, ŷ).\nOur solution then becomes\n    û(x̂, ŷ, t̂) =\n        (1 + f̂₀ / Δλ̂ * (1 - exp(-Δλ̂ * t̂))) * exp(-λ̂ₙₘ * t̂) * φ̂ˢˢₙₘ(x̂, ŷ).\nIn order to improve readability, we will drop the hats from all variable names.","category":"section"},{"location":"api/newtons_method/#Newton's-Method","page":"Newtons Method","title":"Newton's Method","text":"","category":"section"},{"location":"api/newtons_method/#Newton-Krylov-Method","page":"Newtons Method","title":"Newton-Krylov Method","text":"","category":"section"},{"location":"api/newtons_method/#Jacobian-free-Newton-Krylov-Method","page":"Newtons Method","title":"Jacobian-free Newton-Krylov Method","text":"","category":"section"},{"location":"api/newtons_method/#Convergence-Conditions","page":"Newtons Method","title":"Convergence Conditions","text":"","category":"section"},{"location":"api/newtons_method/#Update-Signals","page":"Newtons Method","title":"Update Signals","text":"","category":"section"},{"location":"api/newtons_method/#ClimaTimeSteppers.NewtonsMethod","page":"Newtons Method","title":"ClimaTimeSteppers.NewtonsMethod","text":"NewtonsMethod(;\n    max_iters = 1,\n    update_j = UpdateEvery(NewNewtonIteration),\n    krylov_method = nothing,\n    convergence_checker = nothing,\n    verbose = Silent(),\n)\n\nSolves the equation f(x) = 0, using the Jacobian (or an approximation of the Jacobian) j(x) = f'(x) if it is available. This is done by calling solve_newton!(::NewtonsMethod, cache, x, f!, j! = nothing), where f!(f, x) is a function that sets f(x) in-place and, if it is specified, j!(j, x) is a function that sets j(x) in-place. The x passed to Newton's method is modified in-place, and its initial value is used as a starting guess for the root. The cache can be obtained with allocate_cache(::NewtonsMethod, x_prototype, j_prototype = nothing), where x_prototype is similar to x and f(x), and, if it is specified, j_prototype is similar to j(x). In order for j(x) to be invertible, it must be a square matrix, which implies that x and f(x) must be similar to to each other.\n\nLet x[n] denote the value of x on the n-th Newton iteration (with x[0] denoting the initial value of x), and suppose that x[n] is sufficiently close to some root x̂ of f(x) to make the first-order approximation     f(x̂) ≈ f(x[n]) + j(x[n]) * (x̂ - x[n]). Since f(x̂) = 0, the error on the n-th iteration is roughly     x[n] - x̂ ≈ Δx[n], where Δx[n] = j(x[n]) \\ f(x[n]). Newton's method sets x[n + 1] to be the value of x̂ given by this approximation:     x[n + 1] = x[n] - Δx[n].\n\nIf a Krylov method is specified, it gets used to compute the error Δx[n] = j(x[n]) \\ f(x[n]); otherwise, the error is directly computed by calling ldiv!(Δx, j, f). If the Krylov method uses a Jacobian-free JVP (Jacobian-vector product), j_prototype and j! do not need to be specified. When Newton's method uses a Krylov method, it is called a \"Newton-Krylov method\"; furthermore, when the Krylov method uses a Jacobian-free JVP, it is called a \"Jacobian-free Newton-Krylov method\".\n\nIf j_prototype is specified, it should not be an DenseMatrix. If it is, it has to be factorized with lu before ldiv! is called, which requires the allocation of additional memory. Instead, j_prototype should be an object that can directly be passed to ldiv!. For convenience, though, the use of an DenseMatrix is supported. However, Krylov.jl does not provide such support for its preconditioners, so, since the value computed with j! is used as a preconditioner in Krylov methods with a Jacobian-free JVP, using such a Krylov method requires specifying a j_prototype that can be passed to ldiv!.\n\nIf j(x) changes sufficiently slowly, update_j may be changed from UpdateEvery(NewNewtonIteration) to some other UpdateSignalHandler that gets triggered less frequently, such as UpdateEvery(NewNewtonSolve). This can be used to make the approximation j(x[n]) ≈ j(x₀), where x₀ is a previous value of x[n] (possibly even a value from a previous solve_newton! of Newton's method). When Newton's method uses such an approximation, it is called the \"chord method\".\n\nIn addition, update_j can be set to an UpdateSignalHandler that gets triggered by signals that originate outside of Newton's method, such as UpdateEvery(NewTimeStep). It is possible to send any signal for updating j to Newton's method while it is not running by calling update!(::NewtonsMethod, cache, ::UpdateSignal, j!), where in this case j!(j) is a function that sets j in-place without any dependence on x (since x is not necessarily defined while Newton's method is not running, this version of j! does not take x as an argument). This can be used to make the approximation j(x[n]) ≈ j₀, where j₀ can have an arbitrary value.\n\nIf a convergence checker is provided, it gets used to determine whether to stop iterating on iteration n based on the value x[n] and its error Δx[n]; otherwise, Newton's method iterates from n = 0 to n = max_iters. If the convergence checker determines that x[n] has not converged by the time n = max_iters, a warning gets printed.\n\nIf verbose is set to true, the norms of x[n] and Δx[n] get printed on every iteration. If there is no convergence checker, Δx[n] is not computed on the last iteration, so its final norm is not printed.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.KrylovMethod","page":"Newtons Method","title":"ClimaTimeSteppers.KrylovMethod","text":"KrylovMethod(;\n    type = Val(Krylov.GmresSolver),\n    jacobian_free_jvp = nothing,\n    forcing_term = ConstantForcing(0),\n    args = (20,),\n    kwargs = (;),\n    solve_kwargs = (;),\n    disable_preconditioner = false,\n    verbose = Silent(),\n    debugger = nothing,\n)\n\nFinds an approximation Δx[n] ≈ j(x[n]) \\ f(x[n]) for Newton's method such that ‖f(x[n]) - j(x[n]) * Δx[n]‖ ≤ rtol[n] * ‖f(x[n])‖, where rtol[n] is the value of the forcing term on iteration n. This is done by calling solve_krylov!(::KrylovMethod, cache, Δx, x, f!, f, n, prepare_for_f!, j = nothing), where f is f(x[n]) and, if it is specified, j is either j(x[n]) or an approximation of j(x[n]). The Δx passed to a Krylov method is modified in-place. The cache can be obtained with allocate_cache(::KrylovMethod, x_prototype), where x_prototype is similar to x (and also to Δx and f).\n\nThis is primarily a wrapper for a Krylov.KrylovSolver from Krylov.jl. In allocate_cache, the solver is constructed with solver = type(l, l, args..., Krylov.ktypeof(x_prototype); kwargs...), where l = length(x_prototype) and Krylov.ktypeof(x_prototype) is a subtype of DenseVector that can be used to store x_prototype. By default, the solver is a Krylov.GmresSolver with a Krylov subspace size of 20 (the default Krylov subspace size for this solver in Krylov.jl). In solve_krylov!, the solver is run with Krylov.solve!(solver, opj, f; M, ldiv, atol, rtol, verbose, solve_kwargs...). The solver's type can be changed by specifying a different value for type, though this value has to be wrapped in a Val to avoid runtime compilation.\n\nIn the call to Krylov.solve!, opj is a LinearOperator that represents j(x[n]), which the solver uses by evaluating mul!(jΔx, opj, Δx). If a Jacobian-free JVP (Jacobian-vector product) is specified, it gets used to construct opj and to evaluate the calls to mul!; otherwise, j itself gets used to construct opj, and the calls to mul! simplify to mul!(jΔx, j, Δx).\n\nIf a Jacobian-free JVP and j are both specified, and if disable_preconditioner is set to false, j is treated as an approximation of j(x[n]) and is used as the (left) preconditioner M in order to speed up the solver; otherwise, the preconditioner is simply set to the identity matrix I. The keyword argument ldiv is set to true so that the solver calls ldiv!(Δx′, M, f′) instead of mul!(Δx′, M, f′), where Δx′ and f′ denote internal variables of the solver that roughly correspond to Δx and f. In other words, setting ldiv to true makes the solver treat M as an approximation of j instead of as the inverse of an approximation of j.\n\nThe keyword argument atol is set to 0 because, if it is set to some other value, the inequality ‖f(x[n]) - j(x[n]) * Δx[n]‖ ≤ rtol[n] * ‖f(x[n])‖ changes to ‖f(x[n]) - j(x[n]) * Δx[n]‖ ≤ rtol[n] * ‖f(x[n])‖ + atol, which eliminates any convergence guarantees provided by the forcing term (in order for the Newton-Krylov method to converge, the right-hand side of this inequality must approach 0 as n increases, which cannot happen if atol is not 0).\n\nAll of the arguments and keyword arguments used to construct and run the solver can be modified using args, kwargs, and solve_kwargs. So, the default behavior of this wrapper can be easily overwritten, and any features of Krylov.jl that are not explicitly covered by this wrapper can still be used.\n\nIf verbose is true, the residual ‖f(x[n]) - j(x[n]) * Δx[n]‖ is printed on each iteration of the Krylov method. If a debugger is specified, it is run before the call to Kyrlov.solve!.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.ForcingTerm","page":"Newtons Method","title":"ClimaTimeSteppers.ForcingTerm","text":"ForcingTerm\n\nComputes the value of rtol[n] for a Newton-Krylov method. This is done by calling get_rtol!(::ForcingTerm, cache, f, n), which returns rtol[n]. The cache can be obtained with allocate_cache(::ForcingTerm, x_prototype), where x_prototype is similar to f.\n\nFor a detailed discussion of forcing terms and their convergence guarantees, see \"Choosing the Forcing Terms in an Inexact Newton Method\" by S.C. Eisenstat and H.F. Walker (http://softlib.rice.edu/pub/CRPC-TRs/reports/CRPC-TR94463.pdf).\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.ConstantForcing","page":"Newtons Method","title":"ClimaTimeSteppers.ConstantForcing","text":"ConstantForcing(rtol)\n\nA ForcingTerm that always returns the value rtol, which must be in the interval [0, 1). If x and f! satisfy certain assumptions, this forcing term guarantees that the Newton-Krylov method will converge linearly with an asymptotic rate of at most rtol. If rtol is 0 (or eps(FT)), this forces the approximation of Δx[n] to be exact (or exact to within machine precision) and guarantees that the Newton-Krylov method will converge quadratically. Note that, although a smaller value of rtol guarantees faster asymptotic convergence, it also leads to a higher probability of oversolving.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.EisenstatWalkerForcing","page":"Newtons Method","title":"ClimaTimeSteppers.EisenstatWalkerForcing","text":"EisenstatWalkerForcing(;\n    initial_rtol = 0.5,\n    γ = 1,\n    α = 2,\n    min_rtol_threshold = 0.1,\n    max_rtol = 0.9,\n)\n\nThe ForcingTerm called \"Choice 2\" in the paper \"Choosing the Forcing Terms in an Inexact Newton Method\" by S.C. Eisenstat and H.F. Walker. The values of initial_rtol, min_rtol_threshold, and max_rtol must be in the interval [0, 1), the value of γ must be in the interval [0, 1], and the value of α must be in the interval (1, 2]. These values can all be tuned to prevent the Newton-Krylov method from oversolving. If x and f! satisfy certain assumptions, this forcing term guarantees that the Newton-Krylov method will converge with order α. Note that, although a larger value of α guarantees a higher convergence order, it also leads to a higher probability of oversolving.\n\nThis forcing term was implemented instead of the one called \"Choice 1\" because it has a significantly simpler implementation–-it only requires the value of ‖f(x[n])‖ to compute rtol[n], whereas \"Choice 1\" also requires the norm of the final residual from the Krylov solver.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.KrylovMethodDebugger","page":"Newtons Method","title":"ClimaTimeSteppers.KrylovMethodDebugger","text":"KrylovMethodDebugger\n\nPrints information about the Jacobian matrix j and the preconditioner M (if it is available) that are passed to a Krylov method. This is done by calling print_debug!(::KrylovMethodDebugger, cache, j, M). The cache can be obtained with allocate_cache(::KrylovMethodDebugger, x_prototype), where x_prototype is similar to x.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.PrintConditionNumber","page":"Newtons Method","title":"ClimaTimeSteppers.PrintConditionNumber","text":"PrintConditionNumber()\n\nPrints the condition number of the Jacobian matrix j, and, if a preconditioner M is available, also prints the condition number of inv(M) * j (i.e., the matrix that actually gets \"inverted\" by the Krylov method). This requires computing dense representations of j and inv(M) * j, which is likely to be significantly slower than the Krylov method itself.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.JacobianFreeJVP","page":"Newtons Method","title":"ClimaTimeSteppers.JacobianFreeJVP","text":"JacobianFreeJVP\n\nComputes the Jacobian-vector product j(x[n]) * Δx[n] for a Newton-Krylov method without directly using the Jacobian j(x[n]), and instead only using x[n], f(x[n]), and other function evaluations f(x′). This is done by calling jvp!(::JacobianFreeJVP, cache, jΔx, Δx, x, f!, f, prepare_for_f!). The jΔx passed to a Jacobian-free JVP is modified in-place. The cache can be obtained with allocate_cache(::JacobianFreeJVP, x_prototype), where x_prototype is similar to x (and also to Δx and f).\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.ForwardDiffJVP","page":"Newtons Method","title":"ClimaTimeSteppers.ForwardDiffJVP","text":"ForwardDiffJVP(; default_step = ForwardDiffStepSize3(), step_adjustment = 1)\n\nComputes the Jacobian-vector product using the forward difference approximation j(x) * Δx = (f(x + ε * Δx) - f(x)) / ε, where ε = step_adjustment * default_step(Δx, x).\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.ForwardDiffStepSize","page":"Newtons Method","title":"ClimaTimeSteppers.ForwardDiffStepSize","text":"ForwardDiffStepSize\n\nComputes a default step size for the forward difference approximation of the Jacobian-vector product. This is done by calling default_step(Δx, x), where default_step is a ForwardDiffStepSize.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.ForwardDiffStepSize1","page":"Newtons Method","title":"ClimaTimeSteppers.ForwardDiffStepSize1","text":"ForwardDiffStepSize1()\n\nA ForwardDiffStepSize that is derived based on the notes here: https://web.engr.oregonstate.edu/~webbky/MAE40205020files/Section%204%20Roundoff%20and%20Truncation%20Error.pdf. Although it is not often used with Newton-Krylov methods in practice, it can provide some intuition for for how to set the value of step_adjustment in a ForwardDiffJVP.\n\nThe first-order Taylor series expansion of f(x + ε * Δx) around x is     f(x + ε * Δx) = f(x) + j(x) * (ε * Δx) + e_trunc(x, ε * Δx), where j(x) = f'(x) and e_trunc is the expansion's truncation error. Due to roundoff error, we are unable to directly compute the value of f(x); instead, we can only determine f̂(x), where     f(x) = f̂(x) + e_round(x). Substituting this into the expansion tells us that     f̂(x + ε * Δx) + e_round(x + ε * Δx) =         f̂(x) + e_round(x) + j(x) * (ε * Δx) + e_trunc(x, ε * Δx). Rearranging this gives us the Jacobian-vector product     j(x) * Δx = (f̂(x + ε * Δx) - f̂(x)) / ε - e_trunc(x, ε * Δx) / ε +                  (e_round(x + ε * Δx) - e_round(x)) / ε. So, the normed error of the forward difference approximation of this product is     ‖error‖ = ‖(f̂(x + ε * Δx) - f̂(x)) / ε - j(x) * Δx‖ =              = ‖e_trunc(x, ε * Δx) - e_round(x + ε * Δx) + e_round(x)‖ / ε. We can use the triangle inequality to get the upper bound     ‖error‖ ≤         (‖e_trunc(x, ε * Δx)‖ + ‖e_round(x + ε * Δx)‖ + ‖e_round(x)‖) / ε. If ε is sufficiently small, we can approximate     ‖e_round(x + ε * Δx)‖ ≈ ‖e_round(x)‖. This simplifies the upper bound to     ‖error‖ ≤ (‖e_trunc(x, ε * Δx)‖ + 2 * ‖e_round(x)‖) / ε.\n\nFrom Taylor's theorem (for multivariate vector-valued functions), the truncation error of the first-order expansion is bounded by     ‖e_trunc(x, ε * Δx)‖ ≤ (sup_{x̂ ∈ X} ‖f''(x̂)‖) / 2 * ‖ε * Δx‖^2, where X is a closed ball around x that contains x + ε * Δx (see https://math.stackexchange.com/questions/3478229 for a proof of this). Let us define the value     S = ‖f(x)‖ / sup_{x̂ ∈ X} ‖f''(x̂)‖. By default, we will assume that S ≈ 1, but we will let users pass other values to indicate the \"smoothness\" of f(x) (a large value of S should indicate that the Hessian tensor of f(x) has a small norm compared to f(x) itself). We then have that     ‖e_trunc(x, ε * Δx)‖| ≤ ε^2 / (2 * S) * ‖Δx‖^2 * ‖f(x)‖.\n\nIf only the last bit in each component of f(x) can be altered by roundoff error, then the i-th component of e_round(x) is bounded by     |e_round(x)[i]| ≤ eps(f(x)[i]). More generally, we can assume that there is some constant R (by default, we will assume that R ≈ 1) such that     |e_round(x)[i]| ≤ R * eps(f(x)[i]). We can also make the approximation (which is accurate to within eps(FT))     eps(f(x)[i]) ≈ eps(FT) * |f(x)[i]|. This implies that     |e_round(x)[i]| ≤ R * eps(FT) * |f(x)[i]|. Since this is true for every component of e_round(x) and f(x), we find that     ‖e_round(x)‖ ≤ R * eps(FT) * ‖f(x)‖.\n\nSubstituting the bounds on the truncation and roundoff errors into the bound on the overall error gives us     ‖error‖ ≤ ε / (2 * S) * ‖Δx‖^2 * ‖f(x)‖ + 2 / ε * R * eps(FT) * ‖f(x)‖. Differentiating the right-hand side with respect to ε and setting the result equal to 0 (and noting that the second derivative is always positive) tells us that this upper bound is minimized when     ε = step_adjustment * sqrt(eps(FT)) / ‖Δx‖, where step_adjustment = 2 * sqrt(S * R). By default, we will assume that step_adjustment = 1, but it should be made larger when f is very smooth or has a large roundoff error.\n\nNote that, if we were to replace the forward difference approximation in the derivation above with a central difference approximation, the square root would end up being replaced with a cube root (or, more generally, with an n-th root for a finite difference approximation of order n - 1).\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.ForwardDiffStepSize2","page":"Newtons Method","title":"ClimaTimeSteppers.ForwardDiffStepSize2","text":"ForwardDiffStepSize2()\n\nA ForwardDiffStepSize that is described in the paper \"Jacobian-free Newton–Krylov methods: a survey of approaches and applications\" by D.A. Knoll and D.E. Keyes. According to the paper, this is the step size used by the Fortran package NITSOL.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.ForwardDiffStepSize3","page":"Newtons Method","title":"ClimaTimeSteppers.ForwardDiffStepSize3","text":"ForwardDiffStepSize3()\n\nA ForwardDiffStepSize that is described in the paper \"Jacobian-free Newton–Krylov methods: a survey of approaches and applications\" by D.A. Knoll and D.E. Keyes. According to the paper, this is the average step size one gets when using a certain forward difference approximation for each Jacobian element.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.ConvergenceChecker","page":"Newtons Method","title":"ClimaTimeSteppers.ConvergenceChecker","text":"ConvergenceChecker(;\n    norm_condition,\n    component_condition,\n    condition_combiner,\n    norm = LinearAlgebra.norm,\n)\n\nChecks whether a sequence val[0], val[1], val[2], ... has converged to some limit L, given the errors err[iter] = val[iter] .- L. This is done by calling is_converged!(::ConvergenceChecker, cache, val, err, iter), where val = val[iter] and err = err[iter]. If the value of L is not known, err can be an approximation of err[iter]. The cache for a ConvergenceChecker can be obtained with allocate_cache(::ConvergenceChecker, val_prototype), where val_prototype is similar to val and err.\n\nA ConvergenceChecker can perform two types of checks–-it can check whether norm(val) and norm(err) satisfy some ConvergenceCondition, and it can check whether all the components of abs.(val) and abs.(err) individually satisfy some ConvergenceCondition. These two checks can be combined with either & or |. If one of the checks is not needed, the corresponding ConvergenceCondition can be set to nothing.\n\nInstead of LinearAlgebra.norm, norm can be set to anything that will convert val and err to non-negative scalar values.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.ConvergenceCondition","page":"Newtons Method","title":"ClimaTimeSteppers.ConvergenceCondition","text":"ConvergenceCondition\n\nAn abstract type for objects that can check whether a sequence of non-negative scalar values val[0], val[1], val[2], ... has converged to some limit L, given the errors err[iter] = |val[iter] - L|.\n\nEvery subtype of ConvergenceCondition must define     has_converged(::ConvergenceCondition, cache, val, err, iter). The cache, which is set to nothing by default, may be used to store information from previous iterations that is useful for determining convergence. In order to have access to a cache of some particular type, a subtype of ConvergenceCondition should define     cache_type(::ConvergenceCondition, ::Type{FT}). To specify on which iterations this cache should be updated, it should define     needs_cache_update(::ConvergenceCondition, iter). To specify how the cache should be update on those iterations, it should define     updated_cache(::ConvergenceCondition, cache, val, err, iter).\n\nAlthough cache_type can call promote_type to prevent potential type instability errors, this should be avoided in order to ensure that users write type-stable code.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.MaximumError","page":"Newtons Method","title":"ClimaTimeSteppers.MaximumError","text":"MaximumError(max_err)\n\nChecks whether err[iter] ≤ max_err. Since err[iter] ≥ 0, this can only be true if max_err ≥ 0.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.MaximumRelativeError","page":"Newtons Method","title":"ClimaTimeSteppers.MaximumRelativeError","text":"MaximumRelativeError(max_rel_err)\n\nChecks whether err[iter] ≤ max_rel_err * val[iter]. Since err[iter] ≥ 0 and val[iter] ≥ 0, this can only be true if max_rel_err ≥ 0.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.MaximumErrorReduction","page":"Newtons Method","title":"ClimaTimeSteppers.MaximumErrorReduction","text":"MaximumErrorReduction(max_reduction)\n\nChecks whether err[iter] ≤ max_reduction * err[0] for all iter ≥ 1. Since err[iter] ≥ 0, this can only be true if max_reduction ≥ 0. Also, it must be the case that max_reduction ≤ 1 in order for the sequence to not diverge (i.e., to avoid err[iter] > err[0]).\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.MinimumRateOfConvergence","page":"Newtons Method","title":"ClimaTimeSteppers.MinimumRateOfConvergence","text":"MinimumRateOfConvergence(rate, order = 1)\n\nChecks whether err[iter] ≥ rate * err[iter - 1]^order for all iter ≥ 1. Since err[iter] ≥ 0, this can only be true if rate ≥ 0. Also, if order == 1, it must be the case that rate ≤ 1 in order for the sequence to not diverge (i.e., to avoid err[iter] > err[iter - 1]). In addition, if err[iter] < 1 for all sufficiently large values of iter, it must be the case that order ≥ 1 for the sequence to not diverge.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.MultipleConditions","page":"Newtons Method","title":"ClimaTimeSteppers.MultipleConditions","text":"MultipleConditions(condition_combiner = all, conditions...)\n\nChecks multiple ConvergenceConditions, combining their results with either all or any.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.UpdateSignalHandler","page":"Newtons Method","title":"ClimaTimeSteppers.UpdateSignalHandler","text":"UpdateSignalHandler\n\nA boolean indicating if updates a value upon receiving an appropriate UpdateSignal. This is done by calling needs_update!(::UpdateSignalHandler, ::UpdateSignal).\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.UpdateEvery","page":"Newtons Method","title":"ClimaTimeSteppers.UpdateEvery","text":"UpdateEvery(update_signal_type)\n\nAn UpdateSignalHandler that performs the update whenever it is needs_update! with an UpdateSignal of type update_signal_type.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.UpdateEveryN","page":"Newtons Method","title":"ClimaTimeSteppers.UpdateEveryN","text":"UpdateEveryN(n, update_signal_type, reset_signal_type = Nothing)\n\nAn UpdateSignalHandler that performs the update every n-th time it is needs_update! with an UpdateSignal of type update_signal_type. If reset_signal_type is specified, then the counter (which gets incremented from 0 to n and then gets reset to 0 when it is time to perform another update) is reset to 0 whenever the signal handler is needs_update! with an UpdateSignal of type reset_signal_type.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.UpdateEveryDt","page":"Newtons Method","title":"ClimaTimeSteppers.UpdateEveryDt","text":"UpdateEveryDt(dt)\n\nAn UpdateSignalHandler that performs the update whenever it is needs_update! with an UpdateSignal of type NewTimeStep and the difference between the current time and the previous update time is no less than dt.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.UpdateSignal","page":"Newtons Method","title":"ClimaTimeSteppers.UpdateSignal","text":"UpdateSignal\n\nA signal that gets passed to an UpdateSignalHandler whenever a certain operation is performed.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.NewTimeStep","page":"Newtons Method","title":"ClimaTimeSteppers.NewTimeStep","text":"NewTimeStep(t)\n\nThe signal for a new time step at time t.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.NewNewtonSolve","page":"Newtons Method","title":"ClimaTimeSteppers.NewNewtonSolve","text":"NewNewtonSolve()\n\nThe signal for a new needs_update! of Newton's method, which occurs on every implicit Runge-Kutta stage of the integrator.\n\n\n\n\n\n","category":"type"},{"location":"api/newtons_method/#ClimaTimeSteppers.NewNewtonIteration","page":"Newtons Method","title":"ClimaTimeSteppers.NewNewtonIteration","text":"NewNewtonIteration()\n\nThe signal for a new iteration of Newton's method.\n\n\n\n\n\n","category":"type"},{"location":"algorithm_formulations/rosenbrock/#Rosenbrock-methods","page":"Rosenbrock Method","title":"Rosenbrock methods","text":"In this page, we introduce Rosenbrock-type methods to solve ordinary differential equations. In doing do, we roughly follow Chapter IV.7 of \"Solving Ordinary Differential Equations II\" by Hairer and Wanner. (Beware, notation is not the same.). In this spirit, let us introduce the need for Rosenbrock-type methods in the same way as Hairer and Wanner, by quoting Rosenbrock himself:\n\nWhen the functions are non-linear, implicit equations can in general be solved only by iteration. This is a severe drawback, as it adds to the problem of stability, that of convergence of the iterative process. An alternative, which avoids this difficulty, is ...\n\nRosenbrock method!\n\nBefore reading this page, we recommend reading the page on ODE solvers first [TODO: Add link]","category":"section"},{"location":"algorithm_formulations/rosenbrock/#Introduction-to-the-formalism","page":"Rosenbrock Method","title":"Introduction to the formalism","text":"Let us consider an ordinary differential equation of the form\n\nfracddtu(t) = T(u(t) t)\n\nwhere u is the state, T is the tendency, and t the time. For the sake of simplicity, let us ignore the explicit time dependency in the tendency (we will get back to that at the end).\n\nThe simplest way to introduce the Rosenbrock method is to start from a diagonally implicit Runge-Kutta scheme (see page on DIRK). In an implicit Runge-Kutta method with s stages and tableau a b c, the updated value u_1 for a step of size Delta t is obtained starting from the known value u_0 with\n\nu_1 = u_0 + sum_i=1^s b_i k_i\n\nwith\n\nk_i = Delta t  T ( u_0 + sum_j=1^i-1alpha_ijk_j + alpha_ii k_i)\n\nalpha_ij\n\n, b_i are carefully chosen coefficients.\n\nRosenbrock's idea consists in linearizing T. This operation can be interpreted as taking one iteration for Netwon solver and yields\n\nk_i = Delta t T(g_i) + Delta t T(g_i) alpha_ii k_i\n\nwith J(g_i) Jacobian of the tendency and with\n\ng_i = u_0 + sum_j=1^i-1alpha_ij k_j\n\nIn Rosenbrock-type methods, the Jacobian T is replaced with linear combinations of the Jacobian evaluated at u_0, J:\n\nT(g_i) alpha_ii k_i approx J sum_j=1^i-1gamma_ij k_j + J gamma_ii k_i\n\nwith gamma_ij other coefficients that can be chosen.\n\nNow, each stage consists of solving a system of linear equations in k_i with matrix I - Delta t gamma_ii:\n\n(I - J Delta t gamma_ii) k_i = Delta\nt T(g_i) + J sum_j=1^i-1gamma_ij k_j\n\nfor each i in 1 dots s. Once k_i are known, u_1 can is easily computed and the process repeated for the next step.\n\nIn practice, there are computational advantages at implementing a slight variation of what presented here.\n\nLet us define tildek_i = sum_j=1^i gamma_ij k_j. If the matrix gamma_ij is invertible, we can move freely from k_i to tildek_i. A convenient step is to also define C, as\n\nC = diag(gamma_11^-1 gamma_22^-1 dots gamma_ss^-1) - Gamma^-1\n\nWhich establishes that\n\nk_i = fractildek_igamma_ii - sum_j=1^i -1 c_ij tildek_j\n\nSubstituting this, we obtain the following equations\n\n(J Delta t gamma_ii - 1) tildek_i = - Delta\nt gamma_ii T(g_i) - gamma_ii J sum_j=1^i-1c_ij tildek_j \n\ng_i =  u_0 + sum_j=1^i-1a_ij tildek_j \n\nu_1 = u_0 + sum_j=1^s m_j tildek_j\n\nwith\n\n(a_ij) = (alpha_ij) Gamma^-1\n\nand\n\n(m_i) = (b_i) Gamma^-1\n\nFinally, small changes are required to add support for explicit time derivative:\n\n(J Delta t gamma_ii - 1) tildek_i = - Delta\nt gamma_ii T( t_0 + alpha_i Delta t  g_i) - gamma_ii J sum_j=1^i-1c_ij tildek_j - Delta\nt gamma_ii gamma_i Delta\nt fracpartial Tpartial t(t_0 u_0)\n\nwhere we defined\n\nalpha_i = sum_j=1^i-1alpha_ij \n\n gamma _i = sum_j=1^igamma_ij \n\n note You may wonder what is up with all these ugly minus signs Why dont\n we cancel them out The reason for this is because we want to have the\n prefactor (J Delta t gamma_ii - 1)\n\n. This is called Wfact in the\n\nlanguage of DifferentialEquations.jl. Most other algorithms specify this quantity, so it is convenient to be consistent.","category":"section"},{"location":"algorithm_formulations/rosenbrock/#Implementation","page":"Rosenbrock Method","title":"Implementation","text":"In ClimaTimeSteppers.jl, we implement the last equation presented in the previous section. Currently, the only Rosenbrock-type algorithm implemented is SSPKnoth. SSPKnoth is 3-stage, second-order accurate Rosenbrock with\n\nalpha = beginbmatrix\n    0  0  0 \n    1  0  0 \n    frac14  frac14  0 \n    endbmatrix\n\nGamma = beginbmatrix\n    1  0  0 \n    1  1  0 \n    -frac34  frac34  1 \n    endbmatrix\n\nand\n\nb = (frac16 frac16 frac23)\n\nAt each stage, the state is updated to g_i and precomputed quantities are updated. Tendencies are computed and, unless the stage is the last, DSS is applied to the sum of all the tendencies. After the last stage, DSS is applied to the incremented state.","category":"section"},{"location":"algorithm_formulations/lsrk/#Low-storage-Runge–Kutta-methods","page":"Old LSRK Formulations","title":"Low-storage Runge–Kutta methods","text":"LSRK methods are self-starting, with U^(1) = u^n, and then using stage updates of the form\n\nbeginaligned\ndU^(i) = f(U^(i) t + c_i Delta t) + A_i dU^(i-1)\nU^(i+1) = U^(i) + Delta t B_i dU^(i)\nendaligned\n\nwhere A_1 = c_1 = 0 (implying dU^(1) = f(u^n t)), with the value at the next step being the N+1th stage value u^n+1 = U^(N+1)).\n\nThis allows the updates to be performed with only two copies of the state vector (so long as f can be evaluated in incrementing form).\n\nIt can be written as an RK scheme with Butcher tableau coefficients defined by the recurrences\n\nbeginaligned\na_ii = 0 \na_ij = B_j + A_j+1 a_ij+1\nb_N = B_N \nb_i = B_i + A_i+1 b_i+1\nendaligned\n\nor equivalently\n\nbeginaligned\na_jj = 0 \na_ij = a_i-1j + B_i-1 prod_k=j+1^i-1 A_k\nendaligned\n\nwith b_j treated analogously as a_N+1j.","category":"section"},{"location":"#ClimaTimeSteppers.jl","page":"ClimaTimeSteppers.jl","title":"ClimaTimeSteppers.jl","text":"ClimaTimeSteppers.jl is a suite of ordinary differential equation (ODE) solvers for use as time-stepping methods in a partial differential equation (PDE) solver, such as ClimateMachine.jl. They are specifically written to support distributed and GPU computation, while minimising the memory footprint.\n\nClimaTimeSteppers.jl is built on top of DiffEqBase.jl, and aims to be compatible with the DifferentialEquations.jl ecosystem.","category":"section"},{"location":"#ClimaTimeSteppers","page":"ClimaTimeSteppers.jl","title":"ClimaTimeSteppers","text":"ClimaTimeSteppers\n\nOrdinary differential equation solvers\n\nJuliaDiffEq terminology:\n\nFunction: the right-hand side function df/dt.\nby default, a function gets wrapped in an ODEFunction\ndefine new IncrementingODEFunction to support incrementing function calls.\nProblem: Function, initial u, time span, parameters and options\ndu/dt = f(u,p,t) = fL(u,p,t)  + fR(u,p,t)\nfR(u,p,t) == f(u.p,t) - fL(u,p,t) fL(u,_,_) == A*u for someA(matrix free)\nSplitODEProlem(fL, fR)\n\nODEProblem from SciMLBase.jl\nuse jac option to ODEFunction for linear + full IMEX (https://docs.sciml.ai/latest/features/performanceoverloads/#odeexplicit_jac-1)\nSplitODEProblem for linear + remainder IMEX\nMultirateODEProblem for true multirate\nAlgorithm: small objects (often singleton) which indicate what algorithm + options (e.g. linear solver type)\ndefine new abstract DistributedODEAlgorithm, algorithms in this pacakge will be subtypes of this\ndefine new Multirate for multirate solvers\nIntegrator: contains everything necessary to solve. Used as:\ndefine new DistributedODEIntegrator for solvers in this package\ninit(prob, alg, options...) => integrator   step!(int) => runs single step   solve!(int) => runs it to end   solve(prob, alg, options...) => init + solve!\nSolution (not implemented): contains the \"solution\" to the ODE.\n\n\n\n\n\n","category":"module"}]
}
